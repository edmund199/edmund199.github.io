<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.1.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"edmund199.github.io.git","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title">
<meta property="og:url" content="https://edmund199.github.io.git/index.html">
<meta property="og:site_name">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="edmund">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://edmund199.github.io.git/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title></title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title"></h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">edmund</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">30</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://edmund199.github.io.git/2024/06/06/paper-note/RUL/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/Mixup%20domain%20adaptations%20for%20dynamic%20remaining%20useful%20life%20predictions/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="edmund">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | null">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/06/paper-note/RUL/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/Mixup%20domain%20adaptations%20for%20dynamic%20remaining%20useful%20life%20predictions/" class="post-title-link" itemprop="url">Mixup domain adaptations for dynamic remaining useful life predictions</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-06 14:01:07" itemprop="dateCreated datePublished" datetime="2024-06-06T14:01:07+08:00">2024-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-05-23 09:08:09" itemprop="dateModified" datetime="2024-05-23T09:08:09+08:00">2024-05-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/paper-note/" itemprop="url" rel="index"><span itemprop="name">paper note</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Mixup-domain-adaptations-for-dynamic-remaining-useful-life-predictions"><a href="#Mixup-domain-adaptations-for-dynamic-remaining-useful-life-predictions" class="headerlink" title="Mixup domain adaptations for dynamic remaining useful life predictions"></a>Mixup domain adaptations for dynamic remaining useful life predictions</h2><h3 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h3><p>MDAN encompasses a three-staged mechanism where the <strong>mix-up strategy is not only performed to regularize the source and target domains but also applied to establish an intermediate mix-up domain where the source and target domains are aligned</strong>.The self-supervised learning strategy is implemented to prevent the supervision collapse problem.</p>
<h3 id="1-introduction"><a href="#1-introduction" class="headerlink" title="1.introduction"></a>1.introduction</h3><div align=center>
<img src="https://pic.imgdb.cn/item/664e95c6d9c307b7e9ad47a9.png" >
</div>

<ol>
<li>first trained to master the source domain under the mix-up regularization strategy [14] to enhance predictive consistency and to enrich intrinsic structures of the latent space.</li>
<li>The second stage is designed to create an intermediate mix-up domain where the source and target domains are aligned onto it. This is made possible by applying the progressive mix-up approach [15] which creates convex combinations between the source-domain samples and the target-domain samples using pseudo-labels of the target domain.</li>
<li>The last step is to apply the mix-up regularization strategy in the target domain using pseudo-label information.The self-supervised learning strategy via the controlled reconstruction learning step [16] is integrated to prevent the supervision collapse problems and to create transferable representations.</li>
</ol>
<p><strong>主要贡献：</strong></p>
<ol>
<li>To the best of our knowledge, we are the first to put forward the mixup domain adaptation strategy for time-series problems;</li>
<li>对14，15的改进</li>
<li>对16的改进</li>
</ol>
<h3 id="2-Related-works"><a href="#2-Related-works" class="headerlink" title="2.Related works"></a>2.Related works</h3><h4 id="2-1-Mixup"><a href="#2-1-Mixup" class="headerlink" title="2.1. Mixup"></a>2.1. Mixup</h4><div align=center>
<img src="https://pic.imgdb.cn/item/664e95c6d9c307b7e9ad47b8.png" >
</div>

<h3 id="3-Preliminaries"><a href="#3-Preliminaries" class="headerlink" title="3. Preliminaries"></a>3. Preliminaries</h3><h4 id="3-1-Problem-formulation"><a href="#3-1-Problem-formulation" class="headerlink" title="3.1. Problem formulation"></a>3.1. Problem formulation</h4><p>Unsupervised Domain Adaptation</p>
<h3 id="4-Learning-policy-of-MDAN"><a href="#4-Learning-policy-of-MDAN" class="headerlink" title="4. Learning policy of MDAN"></a>4. Learning policy of MDAN</h3><p>MDAN learning policy comprises three steps: source domain training, intermediate domain training and target domain training.<br><strong>1. The source domain training process learns original labelled samples and mixup samples in the supervised learning manner while also performing the self-supervised training process with the absence of any labels via the controlled reconstruction process</strong> </p>
<p><strong>2.The intermediate domain training process is executed by creating mixup samples between the source domain samples and the target domain samples aided by the pseudo-labelling steps in both input level and feature level. The mixup samples are learned in the supervised learning manner.</strong> </p>
<p><strong>3. Last but not least, the target domain training process is driven by the self-learning mechanism of unlabelled target domain samples and the mixup regularization strategy to combat the issue of noisy pseudo labels.</strong></p>
<div align=center>
<img src="https://pic.imgdb.cn/item/664e95c7d9c307b7e9ad482c.png" >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/664e96b3d9c307b7e9ae09cd.png" >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/664e95c7d9c307b7e9ad48b6.png" >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/664e95c6d9c307b7e9ad4742.png" >
</div>

<h3 id="5-Experiments"><a href="#5-Experiments" class="headerlink" title="5. Experiments"></a>5. Experiments</h3><h4 id="5-1-result"><a href="#5-1-result" class="headerlink" title="5.1 result"></a>5.1 result</h4><div align=center>
<img src="https://pic.imgdb.cn/item/664e96b3d9c307b7e9ae0a67.png" >
</div>

<h4 id="5-6-Analysis-of-domain-discrepancy"><a href="#5-6-Analysis-of-domain-discrepancy" class="headerlink" title="5.6. Analysis of domain discrepancy"></a>5.6. Analysis of domain discrepancy</h4><div align=center>
<img src="https://pic.imgdb.cn/item/664e96b3d9c307b7e9ae09ea.png" >
</div>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://edmund199.github.io.git/2024/06/06/paper-note/RUL/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/Enhanced%20residual%20convolutional%20domain%20adaptation%20network%20with%20CBAM%20for%20RUL%20prediction%20of%20cross-machine%20rolling%20bearing/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="edmund">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | null">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/06/paper-note/RUL/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/Enhanced%20residual%20convolutional%20domain%20adaptation%20network%20with%20CBAM%20for%20RUL%20prediction%20of%20cross-machine%20rolling%20bearing/" class="post-title-link" itemprop="url">Enhanced residual convolutional domain adaptation network with CBAM for RUL prediction of cross-machine rolling bearing</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-06 14:01:07" itemprop="dateCreated datePublished" datetime="2024-06-06T14:01:07+08:00">2024-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-04-25 09:10:41" itemprop="dateModified" datetime="2024-04-25T09:10:41+08:00">2024-04-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/paper-note/" itemprop="url" rel="index"><span itemprop="name">paper note</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Enhanced-residual-convolutional-domain-adaptation-network-with-CBAM-for-RUL-prediction-of-cross-machine-rolling-bearing"><a href="#Enhanced-residual-convolutional-domain-adaptation-network-with-CBAM-for-RUL-prediction-of-cross-machine-rolling-bearing" class="headerlink" title="Enhanced residual convolutional domain adaptation network with CBAM for RUL prediction of cross-machine rolling bearing"></a>Enhanced residual convolutional domain adaptation network with CBAM for RUL prediction of cross-machine rolling bearing</h2><p><strong>2024 苏科大 8.1 1区 Reliability Engineering &amp; System Safety</strong></p>
<h3 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h3><p>Most of the existing methods are domain adaptation (DA) based RUL prediction on the same machine with different conditions, but <strong>few on cross-machine</strong>.</p>
<p>DA can cope with the data distribution discrepancy (domain shift) under different machines or other conditions, but <strong>the potential negative transfer will affect the effect of DA and prediction performance.</strong></p>
<p><strong>an enhanced residual convolutional domain adaptation network (ERCDAN)</strong></p>
<ol>
<li>Firstly, the enhanced residual convolutional module (ERCM) is designed for degradation feature extraction from limited data, and with the convolutional block attention module (CBAM) to enhance the extracted features. （特征提取：残差加卷积注意力）</li>
<li>Secondly, the DA module with a collaborative full connection structure and attenuation multi-kernel maximum mean discrepancy is designed <strong>for mitigating negative transfer to effective domain-invariant feature extraction.</strong>（域适应：协同全连接层设计加衰减多核MMD）</li>
<li>Finally, the experimental analysis of cross-machine rolling bearing RUL prediction is conducted on the PHM2012, XJTUSY, and EBFL datasets.</li>
</ol>
<h3 id="1introduction"><a href="#1introduction" class="headerlink" title="1introduction"></a>1introduction</h3><p>相对其他域适应模型的改进</p>
<ol>
<li><p>The above cross-machine RUL prediction methods all use a training set composed of data from multiple bearings to train the prediction model. However, under the practical engineering with the lack of prior operating data, there may be the situation where trainable resources (trainable bearing data) are scarce, which makes it difficult to ensure that sufficient data is available to train the prediction model.(模型的特征提取能力更强，需要的训练样本更少)</p>
</li>
<li><p>by reducing the data distribution discrepancy, its potential negative transfer will affect the effect of domain-invariant feature extraction and prediction performance, so a negative transfer mitigation scheme is designed in ERCDAN.（模型能有效解决负迁移问题）</p>
</li>
</ol>
<h3 id="2-Proposed-RUL-prediction-method"><a href="#2-Proposed-RUL-prediction-method" class="headerlink" title="2. Proposed RUL prediction method"></a>2. Proposed RUL prediction method</h3><h4 id="2-1-Problem-description"><a href="#2-1-Problem-description" class="headerlink" title="2.1. Problem description"></a>2.1. Problem description</h4><h4 id="2-2-Overview"><a href="#2-2-Overview" class="headerlink" title="2.2. Overview"></a>2.2. Overview</h4><div align=center>
<img src="https://pic.imgdb.cn/item/6629aa4f0ea9cb14035d251d.png" >
</div>

<h4 id="2-3-Enhanced-residual-convolutional-domain-adaptation-network"><a href="#2-3-Enhanced-residual-convolutional-domain-adaptation-network" class="headerlink" title="2.3. Enhanced residual convolutional domain adaptation network"></a>2.3. Enhanced residual convolutional domain adaptation network</h4><p>2.3.1. Enhanced residual convolutional module</p>
<p>(1) To use two convolutional layers of Conv-BN to simulate a large channel convolutional layer to improve the network’s feature representation ability.<br>(2) To address the degradation of network performance caused by the deepening of network layers, a residual structure is used </p>
<div align=center>
<img src="https://pic.imgdb.cn/item/6629aa4f0ea9cb14035d2533.png" >
</div>

<p>2.3.2. CBAM attention mechanism</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/6629aa4f0ea9cb14035d2578.png" >
</div>

<p>2.3.3. Unsupervised domain adaptation and negative transfer mitigation</p>
<ol>
<li><p>Unsupervised domain adaptation:<br>多核最大均值差异Multiple Kernel Maximum Mean Discrepancy（MK-MMD）<br><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_42983182/article/details/127430650">https://blog.csdn.net/qq_42983182/article/details/127430650</a></p>
</li>
<li><p>negative transfer mitigation</p>
<ol>
<li>A collaborative full connection structure is designed between the feature extractor, RUL predictor, and DA module (as shown in FC1 and FC2_1 in Fig. 1), in a way that <strong>the parameters are not shared to avoid the impact of MK-MMD on the RUL predictor during loss backpropagation.</strong></li>
<li>An exponential type attenuation penalty coefficient is designed for the MK-MMD loss, as shown in Fig. 1, to obtain a larger DA gain generated by the larger proportion of the MK-MMD loss in the total loss during the early stages of network training for helping learn domain-invariant features and achieving domain adaptation. <strong>As the number of training iterations increases, the proportion of MK-MMD in total loss gradually decreases, weakening the impact of DA gain on the network</strong>,<strong>(系数取值为1-0.5)</strong> enhancing the network’s stability, and relying more on the feature extractor composed of ERCM with CBAM and RUL predictor for feature learning and RUL prediction, thereby achieving negative transfer mitigation and enhancing feature learning. Domain adaptation loss calculation of the constructed network and the exponential type atten- uation penalty coefficient λattenuation are as follows:</li>
</ol>
</li>
</ol>
<div align=center>
<img src="https://pic.imgdb.cn/item/6629aa4f0ea9cb14035d258f.png" >
</div>

<h4 id="2-4-Training-optimization-objective"><a href="#2-4-Training-optimization-objective" class="headerlink" title="2.4. Training optimization objective"></a>2.4. Training optimization objective</h4><h4 id="2-5-ERCDAN-for-cross-machine-rolling-bearing-RUL-prediction"><a href="#2-5-ERCDAN-for-cross-machine-rolling-bearing-RUL-prediction" class="headerlink" title="2.5. ERCDAN for cross-machine rolling bearing RUL prediction"></a>2.5. ERCDAN for cross-machine rolling bearing RUL prediction</h4><ol>
<li>数据预处理(z-score,寿命标签尺度缩放)，划分数据集</li>
<li>模型训练</li>
<li>寿命预测</li>
</ol>
<h3 id="3-Experimental-analysis"><a href="#3-Experimental-analysis" class="headerlink" title="3. Experimental analysis"></a>3. Experimental analysis</h3><h4 id="3-1-Experimental-setup"><a href="#3-1-Experimental-setup" class="headerlink" title="3.1. Experimental setup"></a>3.1. Experimental setup</h4><p>数据集：PHM 2012 bearing dataset [40], XJTU-SY bearing dataset [41], and EBFL dataset</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/6629aa4f0ea9cb14035d24ba.png" >
</div>

<p>3.1.2. Performance evaluation metrics<br>RMSE，MAE，R2（The closer the value of R2 is to 1, the better the regression fitting effect）</p>
<h4 id="3-2-Ablation-experiment-analysis"><a href="#3-2-Ablation-experiment-analysis" class="headerlink" title="3.2. Ablation experiment analysis"></a>3.2. Ablation experiment analysis</h4><p>3.2.1. Comparison of backbone networks<br><strong>对比不同特征提取网络</strong> </p>
<div align=center>
<img src="https://pic.imgdb.cn/item/6629aa8d0ea9cb14035d71bc.png" >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/6629aa8d0ea9cb14035d7209.png" >
</div>

<p>3.2.2. Comparison of penalty coefficients<br><strong>对比不同损失系数</strong></p>
<div align=center>
<img src="https://pic.imgdb.cn/item/6629aa8d0ea9cb14035d7241.png" >
</div>

<p>3.2.3. Comparison of different modules<br><strong>对比不同模型结构</strong></p>
<div align=center>
<img src="https://pic.imgdb.cn/item/6629aab30ea9cb14035d9fa7.png" >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/6629aab40ea9cb14035da01b.png" >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/6629aab40ea9cb14035d9fc3.png" >
</div>

<blockquote>
<p>Fig. 8 shows the visualization effect of RUL prediction for various methods in structural ablation experiments. It can be seen from Fig. 8 that the RUL curve predicted by the proposed method can better fit the real RUL line. From Fig. 8(a), (h), and (k), it can be seen that Method 4, due to the attenuation MK-MMD and the RUL predictor sharing the fully connected layer, is affected by the MK-MMD during backpropagation, resulting in the final output of the RUL prediction value being more easily misled by negative transfer. The prediction trend of the local RUL curve is opposite to the real RUL, and even significant prediction errors occur, as shown in Fig. 8(b) and (e). From Fig. 8(a) and (e), it can be seen that both Method 4 and Method 5 exhibit a predicted trend of RUL curves that is opposite to the real RUL, while the proposed method does not exhibit a predicted trend of RUL curves that is opposite to the real RUL, indicating the effectiveness of the collaborative full connection structure designed in the proposed method in alleviating negative transfer.</p>
</blockquote>
<h4 id="3-3-Comparative-experiment-analysis"><a href="#3-3-Comparative-experiment-analysis" class="headerlink" title="3.3. Comparative experiment analysis"></a>3.3. Comparative experiment analysis</h4><p>Method 1: CNN-based method; Method 2: CNN-Attention-based method; Method 3: CNN-LSTM-based method. Domain-adaptation methods, Method 4: CORAL-based method; Method 5: DAN-based method; Method 6: DANNbased method.</p>
<p>3.3.1. Cross-machine experiment</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/6629aab30ea9cb14035d9f77.png" >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/6629aab40ea9cb14035da05e.png" >
</div>

<p>负迁移产生的原因</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/6629ac9d0ea9cb14036197c6.png" >
</div>

<p>3.3.2. Cross-bearing experiment on the same machine</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://edmund199.github.io.git/2024/06/06/paper-note/RUL/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96+%E5%88%86%E6%AE%B5%E9%A2%84%E6%B5%8B/Remaining%20Useful%20Life%20Prediction%20of%20Rolling%20Bearings%20Based%20on%20ECA-CAE%20and%20Autoformer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="edmund">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | null">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/06/paper-note/RUL/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96+%E5%88%86%E6%AE%B5%E9%A2%84%E6%B5%8B/Remaining%20Useful%20Life%20Prediction%20of%20Rolling%20Bearings%20Based%20on%20ECA-CAE%20and%20Autoformer/" class="post-title-link" itemprop="url">Remaining Useful Life Prediction of Rolling Bearings Based on ECA-CAE and Autoformer</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-06 14:01:07" itemprop="dateCreated datePublished" datetime="2024-06-06T14:01:07+08:00">2024-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-07 14:45:59" itemprop="dateModified" datetime="2024-03-07T14:45:59+08:00">2024-03-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/paper-note/" itemprop="url" rel="index"><span itemprop="name">paper note</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Remaining-Useful-Life-Prediction-of-Rolling-Bearings-Based-on-ECA-CAE-and-Autoformer"><a href="#Remaining-Useful-Life-Prediction-of-Rolling-Bearings-Based-on-ECA-CAE-and-Autoformer" class="headerlink" title="Remaining Useful Life Prediction of Rolling Bearings Based on ECA-CAE and Autoformer"></a>Remaining Useful Life Prediction of Rolling Bearings Based on ECA-CAE and Autoformer</h2><p><strong>2024 福州大学 4.5 1区 Biomimetics</strong></p>
<h3 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h3><p>In response to the need for multiple complete bearing degradation datasets in traditional deep learning networks to predict the impact on individual bearings, a novel deep learning-based rolling bearing remaining life prediction method is proposed <strong>in the absence of fully degraded bearng data</strong><br>This method involves processing the raw vibration data through <strong>Channel-wise Attention Encoder (CAE) from the Encoder-Channel Attention (ECA)</strong>, extracting features related to mutual correlation and relevance, selecting the desired characteristics, and incorporating the selected features into the constructed <strong>Autoformer-based time prediction model</strong> to forecast the degradation trend of bearings’ remaining time.</p>
<h3 id="1introduction"><a href="#1introduction" class="headerlink" title="1introduction"></a>1introduction</h3><p>In summary, in order to minimize the impact of limited degraded bearing data on the accuracy of life prediction, this paper proposes a new deep learning network model framework.</p>
<ul>
<li>Compared with traditional deep learning methods that require a large amount of complete degraded bearing data for model training, this method only uses the first half of the current bearing degradation features to predict future degradation trends. <strong>This solves the problem of non-optimal model parameters due to insufficient data volume</strong></li>
<li>By comparing with the latest Informer and Transformer models [34,35], the advantages of the proposed method are validated.</li>
<li>Additionally, this model is suitable for predicting the life of bearings under the same operating conditions.</li>
</ul>
<h3 id="2preliminary"><a href="#2preliminary" class="headerlink" title="2preliminary"></a>2preliminary</h3><h4 id="2-1-CAE-Model-convolutional-Auto-Encode"><a href="#2-1-CAE-Model-convolutional-Auto-Encode" class="headerlink" title="2.1. CAE Model(convolutional Auto-Encode)"></a>2.1. CAE Model(convolutional Auto-Encode)</h4><p>卷积自编码器的编码器部分由卷积层（Convolution2D）和MaxPooling层（MaxPooling2D）构成，MaxPooling负责空域下采样。而解码器由卷积层（Convolution2D）和上采样层（UpSampling2D）构成。</p>
<hr>
<p>最为简单的自动编码器是由线性层构成的，它看起来就像是一个普通的深度神经网络DNN，只不过包含两大其他架构不具备的特征：</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65e876a19f345e8d037e5c9e.png" >
</div>

<p>①输出层的神经元数量往往与输入层的神经元数量一致<br>②网络架构往往呈对称性，且中间结构简单、两边结构复杂<br>在上面的架构图中，从输入层开始压缩数据、直至架构中心的部分被称为编码器Encoder，编码器的职责是从原始数据中提取必要的信息，从原始数据中提纯出的信息被称之为编码Code或隐式表示；<br>从编码开始拓展数据、直至输出层的部分被称为解码器Decoder，解码器的输出一般被称为重构数据，解码器的职责是将提取出的信息还原为原来的结构。</p>
<hr>
<h4 id="2-2-ECANet-Efficient-Channel-Attention"><a href="#2-2-ECANet-Efficient-Channel-Attention" class="headerlink" title="2.2. ECANet(Efficient Channel Attention)"></a>2.2. ECANet(Efficient Channel Attention)</h4><p>To cope with the problem of weight assignment among different channels, scholars have proposed ECANet</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65e70e759f345e8d038fa844.png" >
</div>


<p>dynamic convolution kernels are used to effectively extract features under different sensory fields and learn the weights between different channels.</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65e70e759f345e8d038fa8ee.png" >
</div>

<h4 id="2-3-Autoformer-Model"><a href="#2-3-Autoformer-Model" class="headerlink" title="2.3. Autoformer Model"></a>2.3. Autoformer Model</h4><ul>
<li>as the prediction time lengthens,<strong>it is difficult to find reliable temporal dependencies from complex temporal patterns by directly using the self-attention mechanism</strong></li>
<li>secondly, due to the <strong>self-attention secondary complexity problem</strong>, the model has to use its <strong>sparse version</strong>, but it will <strong>limit the information utilization efficiency and affect the prediction effect</strong></li>
</ul>
<div align=center>
<img src="https://pic.imgdb.cn/item/65e70e759f345e8d038fa969.png" >
</div>

<p>Based on the above progressive decomposition architecture, the model can gradually decompose the hidden variables in the forecasting process and obtain the forecasting results of cycle and trend components respectively through the autocorrelation mechanism and accumulation, so as to realize the alternate and mutual promotion of decomposition and optimization of forecasting results.</p>
<hr>
<ul>
<li>series decomposition module</li>
</ul>
<div align=center>
<img src="https://pic.imgdb.cn/item/65e874e19f345e8d0375e261.png" >
</div>

<ul>
<li><p>In the Encoder part, a stepwise elimination of thetrend term is taken to obtain the periodic terms . And based on this periodicity,an <strong>autocorrelation mechanism is used to aggregate similar sub processes of different periods</strong></p>
</li>
<li><p>In the Decoder section, the trend term and the period term are modeled separately. In which, </p>
<ul>
<li>for the period term, the autocorrelation mechanism uses the periodic nature of the sequence to aggregate subsequences with similar processes in different cycles; </li>
<li>for the trend term T, the trend information is gradually extracted from the predicted hidden variables using a cumulative approach.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="3Feature-Extraction-Method-and-Remaining-Useful-Life-Prediction-Algorithm"><a href="#3Feature-Extraction-Method-and-Remaining-Useful-Life-Prediction-Algorithm" class="headerlink" title="3Feature Extraction Method and Remaining Useful Life Prediction Algorithm"></a>3Feature Extraction Method and Remaining Useful Life Prediction Algorithm</h3><h4 id="3-1-ECA-CAE"><a href="#3-1-ECA-CAE" class="headerlink" title="3.1. ECA-CAE"></a>3.1. ECA-CAE</h4><p>In order to verify the effectiveness of the ECA-CAE method proposed in this chapter, the proposed method is compared with the ECA encoder MLP and the convolutional self-encoder CAE</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65e70e759f345e8d038faa07.png" >
</div>

<p>why EAC？</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65e874e19f345e8d0375e307.png" >
</div>

<h4 id="3-2-Remaining-Useful-Life-Prediction-Based-on-ECA-CAE-and-Autoformer-Model"><a href="#3-2-Remaining-Useful-Life-Prediction-Based-on-ECA-CAE-and-Autoformer-Model" class="headerlink" title="3.2. Remaining Useful Life Prediction Based on ECA-CAE and Autoformer Model"></a>3.2. Remaining Useful Life Prediction Based on ECA-CAE and Autoformer Model</h4><p>During the training of the network model, due to <strong>the difference in the failure criteria adopted by different bearings or the sampling time interval is too large,</strong> there is easily too much <strong>difference in the vibration signals leading to the threshold value cannot be unified</strong>; the trend difference problem is shown in Figure 6, if bearing 1,2 is used as training, the model is unable to learn any degradation process about bearing 3, and the RUL of bearing 3 is predicted on this basis, without deliberate tuning of the parameter optimization, the theoretical accuracy is not high.</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65e874e19f345e8d0375e3b6.png" >
</div>

<hr>
<div align=center>
<img src="https://pic.imgdb.cn/item/65e70ed99f345e8d0390f5d0.png" >
</div>

<p>part1:</p>
<div align=center >
<img src="https://pic.imgdb.cn/item/65e70eda9f345e8d0390f6dd.png"  width= 750 height=350 >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/65e70ed99f345e8d0390f66b.png" >
</div>

<ul>
<li>in order to preserve the spatial information and minimize the loss of decoding, the global average pooling layer (GAP) is used outside the encoder to obtain 200×1 data. Using GAP instead of fully connected layer (FC) will reduce a lot of training time, reduce the spatial parameters to make the model more robust, and at the same time anti-overﬁtting eﬀect is bett</li>
<li>The 200 dimensional signals obtained by ECA-CAE have similar features and useless features with small variance, which need to do feature processing.</li>
</ul>
<h3 id="4-Experimental-Validation"><a href="#4-Experimental-Validation" class="headerlink" title="4. Experimental Validation"></a>4. Experimental Validation</h3><h4 id="4-1-Data-Sources"><a href="#4-1-Data-Sources" class="headerlink" title="4.1. Data Sources"></a>4.1. Data Sources</h4><p>XJTU-SY bearing dataset</p>
<h4 id="4-2-Data-Processing-and-Partitioning"><a href="#4-2-Data-Processing-and-Partitioning" class="headerlink" title="4.2. Data Processing and Partitioning"></a>4.2. Data Processing and Partitioning</h4><ul>
<li>A and B are the data without CAE processing, and C and D are the data after CAE processing, where B and D are part of the data of A and C respectively taken out separately for T-SNE.<br><strong>T-SNE</strong> processing, the purpose is to <strong>separate the fault stage and normal stage</strong>, the signal of normal stage is smooth, and it has no guiding meaning to the actual prediction.<blockquote>
<p>T-SNE 一种降维方法，在这里用来区分normal and fault stage</p>
</blockquote>
</li>
<li>Since the signal distribution of the normal operation phase of the bearing is irregular, the features related to the life time cannot be extracted, <strong>so the failure phase data is chosen as the training and prediction data.</strong></li>
</ul>
<div align=center>
<img src="https://pic.imgdb.cn/item/65e70ed99f345e8d0390f47d.png" >
</div>

<ul>
<li>After feature screening, five features representing different degradation characteristics were finally obtained, and the correlation between the features and the correlation with time (time) were calculated as shown in Figure 12.</li>
</ul>
<div align=center>
<img src="https://pic.imgdb.cn/item/65e7121d9f345e8d039c916c.png" >
</div>

<ul>
<li>If the resulting features are considered for lifetime prediction at this point, the required sequence length is not sufficient to support the training of the model, which leads to overfitting. At the same time, if the period information is added, the prediction accuracy of the sequences will be greatly increased. Therefore, a <strong>multi-dimensional sequence splicing</strong> approach is proposed as shown in Figure 13 below<br><strong>To achieve a smooth connection between the points of the sequence</strong>, the sequence is uniformly increased to a length of 9600 using <strong>cubic spline interpolation</strong>(三次样条插值).</li>
</ul>
<blockquote>
<p>三次样条插值法是一种常用的数值分析方法，可以通过给定的一组散点数据来拟合出一条光滑的连续函数曲线。其基本思想是用低次多项式逼近一段小区间内的数据，并利用这些多项式的连接处衔接条件来保证整个曲线的光滑性</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65e7121d9f345e8d039c9220.png" >
</div>



</blockquote>
<h4 id="4-3-Timing-and-Remaining-Useful-Life-Prediction-The-above-mentioned-training-set-and-predict"><a href="#4-3-Timing-and-Remaining-Useful-Life-Prediction-The-above-mentioned-training-set-and-predict" class="headerlink" title="4.3. Timing and Remaining Useful Life Prediction The above-mentioned training set and predict"></a>4.3. Timing and Remaining Useful Life Prediction The above-mentioned training set and predict</h4><p>If the prediction is taken to the training set by fitting the double exponential model, the error exists between the fitted curve and the actual degradation curve because the degradation trend at the later stage is unknown, and the proposed method in this paper is the prediction of the degradation process, and the prediction results tend to be close to the real life.</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65e7121d9f345e8d039c933f.png" >
</div>

<p><strong>对比实验</strong></p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65e7121d9f345e8d039c93cc.png" >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/65e7121d9f345e8d039c9417.png" >
</div>

<p><strong>泛用性</strong><br>taking working condition three as an example, the model parameters of bearing 1 signal processing and feature screening are retained for the prediction of bearing 2 and bearing 5. Since the degradation curve of each bearing is different, so each bearing does a separate Autoformer model training, and the prediction results obtained are shown in Table 10,</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65e961c89f345e8d039b3fb5.png" >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/65e874e29f345e8d0375e75d.png" >
</div>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://edmund199.github.io.git/2024/06/06/paper-note/RUL/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96+%E5%88%86%E6%AE%B5%E9%A2%84%E6%B5%8B/A%20piecewise%20method%20for%20bearing%20remaining%20useful%20life%20estimation%20using%20temporal%20convolutional%20networks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="edmund">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | null">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/06/paper-note/RUL/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96+%E5%88%86%E6%AE%B5%E9%A2%84%E6%B5%8B/A%20piecewise%20method%20for%20bearing%20remaining%20useful%20life%20estimation%20using%20temporal%20convolutional%20networks/" class="post-title-link" itemprop="url">A piecewise method for bearing remaining useful life estimation using temporal convolutional networks</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-06 14:01:07" itemprop="dateCreated datePublished" datetime="2024-06-06T14:01:07+08:00">2024-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-13 11:09:31" itemprop="dateModified" datetime="2024-03-13T11:09:31+08:00">2024-03-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/paper-note/" itemprop="url" rel="index"><span itemprop="name">paper note</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="A-piecewise-method-for-bearing-remaining-useful-life-estimation-using-temporal-convolutional-networks"><a href="#A-piecewise-method-for-bearing-remaining-useful-life-estimation-using-temporal-convolutional-networks" class="headerlink" title="A piecewise method for bearing remaining useful life estimation using temporal convolutional networks"></a>A piecewise method for bearing remaining useful life estimation using temporal convolutional networks</h2><p><strong>2023.04 华科 12.1 1区 Journal of Manufacturing Systems</strong></p>
<h3 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h3><p>traditional network models such as <strong>CNN and RNN have limitations in directly dealing with time series problems</strong>. This paper proposes an adaptive degradation stage division strategy and a temporal convolutional network (TCN)-based RUL piecewise estimation method, called ADSD-TCNPE. This method mainly includes three steps.</p>
<ul>
<li>(1) <strong>Extract features</strong> from different domains and select the features that are highly correlated with bearing degradation. </li>
<li>(2) <strong>Adaptively divide the whole lifecycle</strong> of bearing into different degradation stages.</li>
<li>(3) Establish a <strong>TCN-based piecewise degradation model</strong> for <strong>different degradation stages</strong> to accurately predict bearing RUL.</li>
</ul>
<h3 id="1introduction"><a href="#1introduction" class="headerlink" title="1introduction"></a>1introduction</h3><p>PHM -&gt;model-based methods [2,3] and data-driven methods -&gt;<br>Although the above deep learning-based methods have achieved excellent results, <strong>there are still some challenges</strong>:</p>
<ul>
<li>Firstly, most existing methods focus on building a <strong>whole-lifecycle degradation model for bearings</strong>, which is <strong>different from the actual bearing degradation process</strong>.</li>
<li>Secondly, the <strong>corresponding mapping relationships</strong> between extracted features and operating states have not been fully learned for these different degradation states.</li>
<li>Thirdly, some commonly used deep learning <strong>models have limitations</strong> for the RUL prediction problem.like CNN,RNN</li>
</ul>
<hr>
<p>The main contributions of this paper can be summarized as follows.</p>
<ul>
<li>First, <strong>multiple degradation features</strong>, including time-domain features, frequency domain features, and time-frequency domain features, are extracted from the vibration signal. <strong>Then the effective features are selected according to the established comprehensive evaluation metric.</strong> <strong>多尺度退化特征的筛选及评级指标</strong></li>
<li>the density-based clustering algorithm is used to adaptively divide the bearing degradation state. <strong>退化过程的自适应划分</strong></li>
<li>A piecewise estimation model is established for the RUL prediction of bearings. <strong>The corresponding estimation model is built for each health state to predict RUL.</strong> Our <strong>TCN-based RUL estimation method has superior</strong> feature extraction ability and long-term sequence processing capability, which is more suitable for the bearing RUL prediction task.</li>
</ul>
<h3 id="2Temporal-convolutional-network"><a href="#2Temporal-convolutional-network" class="headerlink" title="2Temporal convolutional network"></a>2Temporal convolutional network</h3><div align=center>
<img src="https://pic.imgdb.cn/item/65f115ad9f345e8d039be4c5.png">
</div>

<h3 id="3-Proposed-ADSD-TCNPE-approach"><a href="#3-Proposed-ADSD-TCNPE-approach" class="headerlink" title="3. Proposed ADSD-TCNPE approach"></a>3. Proposed ADSD-TCNPE approach</h3><div align=center>
<img src=https://pic.imgdb.cn/item/65f115ad9f345e8d039be584.png >
</div>

<ul>
<li><p>Firstly, <strong>the time, frequency, and time-frequency domain features are extracted</strong> from bearing vibration signals to form the original feature space. Meanwhile, <strong>a comprehensive evaluation metric is constructed to select features with high degradation correlation from the original feature space.</strong><br>时域，频域，时频域特征的提取及用综合评价指标进行特征筛选</p>
</li>
<li><p>Secondly, <strong>a nonlinear compression method is used to make the boundaries between different degradation stages more exact, and density-based clustering is employed to adaptively divide different degradation stages</strong>.<br>用非线性压缩方法(T-SNE)使不同退化阶段的特征边界更明显，再使用密度聚类的方法区分不同退化阶段</p>
</li>
<li><p>Finally, the TCN-based degradation models of different degradation stages are established to realize bearing RUL prediction. The detailed description of each step is as follows.<br>最后在不同退化阶段建立不同的TCN模型进行预测</p>
</li>
</ul>
<h4 id="3-1-Feature-extraction"><a href="#3-1-Feature-extraction" class="headerlink" title="3.1. Feature extraction"></a>3.1. Feature extraction</h4><p>why？</p>
<blockquote>
<p>the original signal data is often high-dimensional and has redundant information, making it difficult to establish an accurate degradation model.</p>
</blockquote>
<p>3.1.1. Time-domain features<br>Time-domain features that give a general profile of bearing degradation trends have been verified to be effective in monitoring machinery health states.</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65f115ad9f345e8d039be5f9.png" >
</div>

<hr>
<p>3.1.2. Frequency-domain features</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65f115ad9f345e8d039be64a.png" >
</div>

<hr>
<p>3.1.3. Time-frequency features</p>
<p>The time and frequency domain features give a general profile of bearing degradation trends, while the time-frequency domain features can represent the local characteristics of the vibration signal.</p>
<p><strong>empirical mode decomposition (EMD) and Hilbert spectrum analysis</strong></p>
<p>todo</p>
<h4 id="3-2-Feature-selection-using-comprehensive-evaluation-metric"><a href="#3-2-Feature-selection-using-comprehensive-evaluation-metric" class="headerlink" title="3.2. Feature selection using comprehensive evaluation metric"></a>3.2. Feature selection using comprehensive evaluation metric</h4><p>why?</p>
<blockquote>
<p>It can be found that <strong>good prediction features have similar degradation properties</strong>, so the distance between feature sequences should be as close as possible, and they should also <strong>be monotonically correlated with the degradation process</strong>.</p>
</blockquote>
<p><strong>The dynamic time warping distance</strong> is first used to measure the <strong>similarity between feature sequences</strong>. Moreover, <strong>monotonicity and correlation metrics are employed to measure the monotonic correlation of features</strong></p>
<hr>
<p>3.2.1. Dynamic time warping distance metric<br>Compared with traditional distance measurement methods such as Euclidean distance, <strong>dynamic time warping (DTW) shows superior performance in measuring the similarity of time series.</strong></p>
<p><strong>补充：</strong><br><strong>Dynamic Time Warping（动态时间调），用来进行时间序列相似性度量</strong></p>
<p>在传统算法中，可以用余弦相似度和pearson相关系数来描述两个序列的相似度。但是时间序列比较特殊，可能存在两个问题：</p>
<ul>
<li>两段时间序列长度不同。如何求相似度？</li>
<li>一个序列是另一个序列平移之后得到的。如何求相似距离？</li>
</ul>
<p>第一个问题，导致了根本不能用余弦相似度和pearson相关系数来求解相似。第二个问题，导致了也不能基于欧式距离这样的算法，来求解相似距离。<br>Dynamic Time Warping (DTW) 本质上和通过动态规划来计算这个序列的相似距离。</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65f118d39f345e8d03a74722.png" >
</div>

<p>在文中用DWT获得了不同特征序列与特征序列中心的相似度，原因是Features with smaller similarity distances are more appropriate for RUL prediction.</p>
<p>参考:<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_39910711/article/details/108178110">https://blog.csdn.net/weixin_39910711/article/details/108178110</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/xsdxs/article/details/86648605">https://blog.csdn.net/xsdxs/article/details/86648605</a></p>
<hr>
<p>3.2.2. Correlation metric</p>
<p>The time correlation metric measures the degree of linear correlation between feature sequences and running time, denoted as Corr and the calculation equation is as follows:</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65f115ad9f345e8d039be6b7.png" >
</div>

<p>3.2.3. Monotonicity metric</p>
<p>The monotonicity metric (denoted as Mon) assesses the feature increasing or decreasing trend as follows</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65f116bb9f345e8d03a042e6.png" >
</div>

<p>the  comprehensive evaluation metric</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65f1173b9f345e8d03a1e980.png" >
</div>

<h4 id="3-3-Degradation-state-division"><a href="#3-3-Degradation-state-division" class="headerlink" title="3.3. Degradation state division"></a>3.3. Degradation state division</h4><p>why？</p>
<blockquote>
<p>The degraded expression after feature selection may still have some redundant information.which may lead to a long distance between degradation state points in the same degradation stage and a short distance between state points in different degradation stages, further resulting in <strong>the boundaries between different degradation stages are not distinguishable enough</strong>.<br>经过特征提取后的特征可能有冗余的信息，会导致在相同退化阶段的退化特征点之间距离较长，不同退化阶段的点之间的距离较短，从而使不同退化阶段的边界不够明显。</p>
</blockquote>
<hr>
<p>3.3.1. Feature compression based on t-SNE<br>This algorithm first transforms the Euclidean distance into a joint probability distribution and then compresses the data from high-dimension to low-dimension to express the similarity between state points.<br>经过t-SNE的降维后，不同阶段的退化状态点距离拉长，相同点距离缩短。</p>
<p><strong>补充两种常见的降维方法</strong>：<br>Principal Component Analysis(PCA)，t-Distributed Stochastic Neighbour Embedding(t-SNE，t分布随机邻居嵌入)<br>减少数据维数的目标 (Goals for reducing the dimensionality of the data)</p>
<ol>
<li><p>Preserve as much significant structure or information of the data present in the high-dimensional data as possible in the low-dimensional representation.<br><strong>在低维表示中，尽可能保留高维数据中存在的数据的重要结构或信息。</strong></p>
</li>
<li><p>Increase the interpretability of the data in the lower dimension<strong>在较低维度上增加数据的可解释性</strong></p>
</li>
<li><p>Minimizing information loss of data due to dimensionality reduction<strong>最小化因降维而导致的数据信息丢失</strong></p>
</li>
</ol>
<p><strong>主成分分析(PCA)</strong>:</p>
<blockquote>
<p>一种无监督的确定性算法，用于特征提取和可视化<br>应用线性降维技术 ，其重点是在低维空间中将相异的点保持较远的距离 。<br>通过使用特征值保留数据中的方差，将原始数据转换为新数据 。<br>离群值影响PCA。</p>
</blockquote>
<p><strong>t-分布随机邻居嵌入(t-SNE) (t-Distributed Stochastic Neighbourh Embedding(t-SNE))</strong></p>
<blockquote>
<p>一种无监督的随机算法，仅用于可视化<br>应用非线性 降 维技术 ，其中重点是在低维空间中将非常相似的数据点保持在一起 。<br>使用学生t分布保留数据的局部结构，以计算低维空间中两点之间的相似度。<br>t-SNE使用重尾学生t分布来计算低维空间中两点之间的相似度，而不是高斯分布，这有助于解决拥挤和优化问题 。<br>t-SNE使用重尾学生t分布来计算低维空间中两点之间的相似度，而不是高斯分布，这有助于解决拥挤和优化问题<br>离群值不影响t-SNE</p>
</blockquote>
<p>参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_26752765/article/details/108132823">https://blog.csdn.net/weixin_26752765/article/details/108132823</a></p>
<p>3.3.2. Degradation state division based on DBSCAN</p>
<blockquote>
<p>why?<br>Since the spatial distribution shape of <strong>feature state points after feature compression may be irregular</strong>, this paper adopts the density-based spatial clustering of applications with noise (DBSCAN) algorithm to deal with the state points after feature compression.</p>
</blockquote>
<h4 id="3-4RUL-piecewise-estimation-based-on-TCN"><a href="#3-4RUL-piecewise-estimation-based-on-TCN" class="headerlink" title="3.4RUL piecewise estimation based on TCN"></a>3.4RUL piecewise estimation based on TCN</h4><p>why piecewise estimation？<br>Mixing data from the slow and rapid degradation stages to train the RUL estimation model together will <strong>generate an unbalanced data problem and result in an inaccurate prediction model</strong> for the rapid degradation stage.</p>
<p>Here the input data for both SVM and TCN models are the feature points vector f after feature selection, and the output data are the degradation stage labels and RUL labels, respectively.</p>
<p>normalization：minmax<br>metric：RMSE，MAPE，Er(percent error)</p>
<h3 id="4-Experimental-verification"><a href="#4-Experimental-verification" class="headerlink" title="4. Experimental verification"></a>4. Experimental verification</h3><h4 id="4-1-Data-description"><a href="#4-1-Data-description" class="headerlink" title="4.1. Data description"></a>4.1. Data description</h4><p>FEMTO</p>
<h4 id="4-2-Feature-extraction-and-selection"><a href="#4-2-Feature-extraction-and-selection" class="headerlink" title="4.2. Feature extraction and selection"></a>4.2. Feature extraction and selection</h4><div align=center>
<img src="https://pic.imgdb.cn/item/65f1173c9f345e8d03a1eb4c.png" >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/65f1173c9f345e8d03a1ec58.png" >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/65f1173c9f345e8d03a1ed40.png" >
</div>

<p>In this study, 14 features least correlated to bearing degradation are eliminated to keep the number of selected features the same.</p>
<h4 id="4-3-Division-of-degradation-stages"><a href="#4-3-Division-of-degradation-stages" class="headerlink" title="4.3. Division of degradation stages"></a>4.3. Division of degradation stages</h4><p>In this section, the <strong>t-SNE algorithm</strong> is adopted to compress the selected effective features into two dimensions. <strong>The low-dimensional spatial distribution of compressed features can distinguish different degradation states.</strong></p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65f117859f345e8d03a2e695.png" >
</div>

<h4 id="4-4-RUL-estimation-results-and-analysis"><a href="#4-4-RUL-estimation-results-and-analysis" class="headerlink" title="4.4. RUL estimation results and analysis"></a>4.4. RUL estimation results and analysis</h4><p>4.4.1. Estimation results and analysis</p>
<blockquote>
<p>为什么不用T—sne降维后的特征作为输入？<br>To avoid the loss of degradation information, this paper uses the 30-dimensional features after feature selection as network inputs instead of the 2-dimensional features after t-SNE dimensionality reduction.</p>
</blockquote>
<div align=center>
<img src="https://pic.imgdb.cn/item/65f117859f345e8d03a2e70b.png" >
</div>

<hr>
<p>The comparison of <strong>piecewise estimation</strong> using the ADSD-TCNPE model proposed in this paper, and Who represents the result of the unified degradation model for <strong>the whole lifecycle</strong>.</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65f117859f345e8d03a2e96f.png" >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/65f117859f345e8d03a2e8ca.png" >
</div>


<p>prediction model can achieve <strong>better prediction</strong> results, especially <strong>in the rapid degradation stage</strong> when the bearing is about to fail. <strong>This is because the prediction model in the rapid degradation stage focuses on a small number of training samples in that stage and is not affected by the noise of other samples in the slow degradation stage.</strong></p>
<p>4.4.2. Method validation</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65f118aa9f345e8d03a6bede.png" >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/65f118aa9f345e8d03a6bf4a.png" >
</div>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://edmund199.github.io.git/2024/06/06/paper-note/RUL/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96+%E5%88%86%E6%AE%B5%E9%A2%84%E6%B5%8B/8.Remaining%20useful%20life%20prediction%20of%20bearing%20based%20on%20stacked%20autoencoder%20and%20recurrent%20neural%20network/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="edmund">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | null">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/06/paper-note/RUL/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96+%E5%88%86%E6%AE%B5%E9%A2%84%E6%B5%8B/8.Remaining%20useful%20life%20prediction%20of%20bearing%20based%20on%20stacked%20autoencoder%20and%20recurrent%20neural%20network/" class="post-title-link" itemprop="url">AE构建HI</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-06 14:01:07" itemprop="dateCreated datePublished" datetime="2024-06-06T14:01:07+08:00">2024-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-27 19:37:44" itemprop="dateModified" datetime="2024-03-27T19:37:44+08:00">2024-03-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/paper-note/" itemprop="url" rel="index"><span itemprop="name">paper note</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Remaining-useful-life-prediction-of-bearing-based-on-stacked-autoencoder-and-recurrent-neural-network"><a href="#Remaining-useful-life-prediction-of-bearing-based-on-stacked-autoencoder-and-recurrent-neural-network" class="headerlink" title="Remaining useful life prediction of bearing based on stacked autoencoder and recurrent neural network"></a>Remaining useful life prediction of bearing based on stacked autoencoder and recurrent neural network</h1><p><strong>2021.04 北京科技大学 12.1 1区 Journal of Manufacturing Systems</strong></p>
<h2 id="1introduction"><a href="#1introduction" class="headerlink" title="1introduction"></a>1introduction</h2><p>非线性HI的优势</p>
<blockquote>
<p>nonlinear degradation processes are common in nature, and the nonlinear shape of degradation proves their advantage in tracking the dynamics of many actual degradation processes used for prediction [17,18]</p>
</blockquote>
<div align=center>
<img src="https://pic.imgdb.cn/item/660404549f345e8d036311d8.png" >
</div>

<p>flow chat</p>
<ol>
<li>训练部分(ims)<ol>
<li>提取十种时域特征，筛选出四种特征，因为只采用退化阶段数据进行训练，数据量小所以对数据进行了三次指数线性插值，将特征输入带注意力的aotu encoder构建HI指标</li>
<li>将数据的STD特征作为输入，HI作为标签对LSTM模型进行训练</li>
</ol>
</li>
</ol>
<div align=center>
<img src="https://pic.imgdb.cn/item/660404559f345e8d0363132a.png" >
</div>

<ol>
<li>测试部分(ims)<ol>
<li>将测试数据的std输入网络，将输出HI与原HI对比</li>
</ol>
</li>
<li>验证部分(cwru)<ol>
<li>用CWRU数据集中不同载荷下的数据提取出的STD输入网络，看输出的HI是否合理</li>
</ol>
</li>
</ol>
<h1 id="A-new-supervised-multi-head-self-attention-autoencoder-for-health-indicator-construction-and-similarity-based-machinery-RUL-prediction"><a href="#A-new-supervised-multi-head-self-attention-autoencoder-for-health-indicator-construction-and-similarity-based-machinery-RUL-prediction" class="headerlink" title="A new supervised multi-head self-attention autoencoder for health indicator construction and similarity-based machinery RUL prediction"></a>A new supervised multi-head self-attention autoencoder for health indicator construction and similarity-based machinery RUL prediction</h1><p>重庆大学 2023.01. 8.8 1区</p>
<h2 id="知识点"><a href="#知识点" class="headerlink" title="知识点"></a>知识点</h2><blockquote>
<p>why hi?<br>However, it is unreasonable to treat the degradation rate of a machine as a constant value in practice, since the accumulation of damage would lead to the accelerated degradation at the end of its life. In addition, the detection of the initial degradation point is an extremely difficult task, and it is also related to the experience of engineer [35]. Therefore, it is necessary to design an appropriate HI label to reflect the machine degradation trend.</p>
</blockquote>
<h2 id="简记"><a href="#简记" class="headerlink" title="简记"></a>简记</h2><div align=center>
<img src="https://pic.imgdb.cn/item/660404559f345e8d03631548.png" >
</div>

<p>flowchart</p>
<ol>
<li>振动信号先经过低通滤波，消除异常值等处理。之后按照公式5建立HI曲线作为标签，（对不同的数据组，进行HI构造实验，通过综合指标判断构建的HI的有效性），其与普通的线性HI区别如图fig4</li>
</ol>
<div align=center>
<img src="https://pic.imgdb.cn/item/660404559f345e8d036315d7.png" >
</div>
<div align=center>
<img src="https://pic.imgdb.cn/item/660404559f345e8d03631749.png" >
</div>

<ol>
<li>用HI曲线作为标签，用振动信号作为输入，训练带注意力的自编码器，其中带有两项损失，分别是encoder的输入和decoder输出的差别的损失，还有中间变量与公式构建的HI差别的损失。</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://edmund199.github.io.git/2024/06/06/paper-note/RUL/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96+%E5%88%86%E6%AE%B5%E9%A2%84%E6%B5%8B/7.Towards%20trustworthy%20remaining%20useful%20life%20prediction%20through%20multi-source%20information%20fusion%20and%20a%20novel%20LSTM-DAU%20model/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="edmund">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | null">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/06/paper-note/RUL/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96+%E5%88%86%E6%AE%B5%E9%A2%84%E6%B5%8B/7.Towards%20trustworthy%20remaining%20useful%20life%20prediction%20through%20multi-source%20information%20fusion%20and%20a%20novel%20LSTM-DAU%20model/" class="post-title-link" itemprop="url">Towards trustworthy remaining useful life prediction through multi-source information fusion and a novel LSTM-DAU model</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-06 14:01:07" itemprop="dateCreated datePublished" datetime="2024-06-06T14:01:07+08:00">2024-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-04-11 19:13:12" itemprop="dateModified" datetime="2024-04-11T19:13:12+08:00">2024-04-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/paper-note/" itemprop="url" rel="index"><span itemprop="name">paper note</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><strong>2024.02.08 西北工业大学 8.1 1区 Reliability Engineering &amp; System Safety</strong></p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>To solve the above problems, a novel adaptive multi-source fusion method based on genetic programming is proposed for building a HI that can effectively reflect the health state of machines. Subsequently, a new LSTM model with a dual-attention mechanism</p>
<h2 id="1introduction"><a href="#1introduction" class="headerlink" title="1introduction"></a>1introduction</h2><p>Condition-based maintenance (CBM) exploits condition monitoring (CM) information to identify or predict potential problems</p>
<h3 id="1-1-Review-of-different-signals-for-machinery-CM-and-RUL-prediction"><a href="#1-1-Review-of-different-signals-for-machinery-CM-and-RUL-prediction" class="headerlink" title="1.1. Review of different signals for machinery CM and RUL prediction"></a>1.1. Review of different signals for machinery CM and RUL prediction</h3><div align=center>
<img src="https://pic.imgdb.cn/item/660403cb9f345e8d035eb868.png" >
</div>

<p>Considering the advantages of high utility and low cost of vibration and temperature signals, this paper proposes a novel method for machine degradation monitoring and RUL prediction based on the fusion of vibration and temperature signals.</p>
<h3 id="1-2-Review-of-LSTM-based-RUL-prediction-methods"><a href="#1-2-Review-of-LSTM-based-RUL-prediction-methods" class="headerlink" title="1.2. Review of LSTM-based RUL prediction methods"></a>1.2. Review of LSTM-based RUL prediction methods</h3><blockquote>
<p><strong>lstm不足:</strong><br> uses the same updating method for all input and recurrent information which fails to process the data in accordance with the importance of the information<br><strong>Attention不足：</strong><br> the attentional mechanisms on the input side to weigh different input features. These methods ignore the backward and forward dependencies of the sequences and seldom investigate the attentional mechanism of the recurrent information in the sequences.</p>
</blockquote>
<h3 id="1-3-Contributions"><a href="#1-3-Contributions" class="headerlink" title="1.3. Contributions"></a>1.3. Contributions</h3><ul>
<li>First, feature extraction is performed based on vibration and temperature signals, and two optimal features are selected respectively.提取振动和温度信号的特征。 </li>
<li>Second, considering that vibration and temperature features may contribute differently to the RUL prediction, genetic programming (GP) is adopted to adaptively fuse the above two features, which in turn yields the HI characterizing the equipment’s health state. 用GP算法进行特征融合，构造HI</li>
<li>Finally, based on the proposed LSTMDAU, an unsupervised learning framework is developed to predict the health state and RUL of machines.用LSTM结合注意力的网络进行预测</li>
</ul>
<h2 id="2-GP-based-feature-fusion"><a href="#2-GP-based-feature-fusion" class="headerlink" title="2. GP-based feature fusion"></a>2. GP-based feature fusion</h2><p><strong>why GP?</strong></p>
<blockquote>
<p>GP is a popular heuristic <strong>nonlinear algorithm</strong>. It not only preserves the original features as much as possible but also finds the optimal HI in a shorter time. Most importantly, the HI generated adaptively by GP can be expressed in an easy-to-read and well-interpretable form, which <strong>solves the black-box modeling problem</strong> of some approaches, such as NN.</p>
</blockquote>
<h2 id="3-Developed-LSTM-DAU-method"><a href="#3-Developed-LSTM-DAU-method" class="headerlink" title="3. Developed LSTM-DAU method"></a>3. Developed LSTM-DAU method</h2><p>3.1. Input attention unit<br>3.2. Recurrent attention unit<br>3.3. Dual attention unit</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/660403cb9f345e8d035eb9a2.png" >
</div>

<h2 id="4-Proposed-methodology"><a href="#4-Proposed-methodology" class="headerlink" title="4. Proposed methodology"></a>4. Proposed methodology</h2><div align=center>
<img src="https://pic.imgdb.cn/item/660403cb9f345e8d035ebbeb.png" >
</div>

<h3 id="4-1-HI-construction"><a href="#4-1-HI-construction" class="headerlink" title="4.1. HI construction"></a>4.1. HI construction</h3><h4 id="4-1-1-Feature-extraction"><a href="#4-1-1-Feature-extraction" class="headerlink" title="4.1.1. Feature extraction"></a>4.1.1. Feature extraction</h4><p>振动信号特征<br>AWSPT-Kurtosis, AWSPT-SI, AWSPT-NE, AWSPT-SI, AWSPT-GI [41]<br>温度信号特征<br>mean, root mean square (RMS), maximum (Max), and minimum (Min) of temperature signals</p>
<h4 id="4-1-2-Feature-selection"><a href="#4-1-2-Feature-selection" class="headerlink" title="4.1.2. Feature selection"></a>4.1.2. Feature selection</h4><p><strong>why</strong>?</p>
<blockquote>
<p>The purpose of feature selection is to obtain preferred features from the original feature set according to some rules that minimize the redundancy between features while containing the most valuable degradation features [42]. This section describes the detailed steps of feature selection</p>
</blockquote>
<p>筛选指标<br>composite evaluation index (CEI)</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/660403cc9f345e8d035ebc92.png" >
</div>

<h4 id="4-1-3-Feature-fusion"><a href="#4-1-3-Feature-fusion" class="headerlink" title="4.1.3. Feature fusion"></a>4.1.3. Feature fusion</h4><p><strong>why？</strong></p>
<blockquote>
<p>the vibration signal is more sensitive to structural damage and the temperature signal is more sensitive to non-structural damage</p>
</blockquote>
<p>Employ the GP algorithm to adaptively fuse the preferred features by the fitness function</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/660403cc9f345e8d035ebd30.png" >
</div>

<h3 id="4-2-The-specific-procedure-of-RUL-prediction-based-on-LSTM-DAU"><a href="#4-2-The-specific-procedure-of-RUL-prediction-based-on-LSTM-DAU" class="headerlink" title="4.2. The specific procedure of RUL prediction based on LSTM-DAU"></a>4.2. The specific procedure of RUL prediction based on LSTM-DAU</h3><p>pass</p>
<h2 id="5-Case-study"><a href="#5-Case-study" class="headerlink" title="5. Case study"></a>5. Case study</h2><h3 id="5-1-Data-description-and-preprocessing"><a href="#5-1-Data-description-and-preprocessing" class="headerlink" title="5.1. Data description and preprocessing"></a>5.1. Data description and preprocessing</h3><div align=center>
<img src="https://pic.imgdb.cn/item/660404099f345e8d0360abfd.png" >
</div>

<h3 id="5-2-HI-construction"><a href="#5-2-HI-construction" class="headerlink" title="5.2. HI construction"></a>5.2. HI construction</h3><div align=center>
<img src="https://pic.imgdb.cn/item/660404099f345e8d0360ad5f.png" >
</div>

<p>对比不同的降维方法在bearing1_1</p>
<blockquote>
<p>Moreover, GP is nonlinear learning compared to PCA. To better characterize the nonlinear nature of the degradation process, GP is adopted to generate HI.</p>
</blockquote>
<div align=center>
<img src="https://pic.imgdb.cn/item/660404099f345e8d0360afd2.png" >
</div>

<h3 id="5-3-LSTM-DAU-network-setting-and-evaluation-metric"><a href="#5-3-LSTM-DAU-network-setting-and-evaluation-metric" class="headerlink" title="5.3. LSTM-DAU network setting and evaluation metric"></a>5.3. LSTM-DAU network setting and evaluation metric</h3><h3 id="5-4-RUL-prognosis-and-comparison-analysis"><a href="#5-4-RUL-prognosis-and-comparison-analysis" class="headerlink" title="5.4. RUL prognosis and comparison analysis"></a>5.4. RUL prognosis and comparison analysis</h3><p>only the data in the degradation phase of a bearing are adopted to train the LSTM-DAU. The determination of the degradation phase can be found in Ref. [42].</p>
<p>实验部分：<br>对比不同窗口大小，对比不同训练数据集大小，消融实验（两个单特征，两个单注意力LSTM，和LSTM），对比实验（对比SOTA）</p>
<p>[41]:Hou B, Wang D, Wang Y, Yan T, Peng Z, Tsui K-L. Adaptive weighted signal preprocessing technique for machine health monitoring. IEEE Trans Instrum Meas 2020;70:1–11.<br>[42]:Mi J, Liu L, Zhuang Y, Bai L, Li Y-F. A synthetic feature processing method for remaining useful life prediction of rolling bearings. IEEE Trans Reliab 2022;72(1):125–36.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://edmund199.github.io.git/2024/06/06/paper-note/RUL/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/Contrastive%20BiLSTM-enabled%20Health%20Representation%20Learning%20for%20Remaining%20Useful%20Life%20Prediction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="edmund">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | null">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/06/paper-note/RUL/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/Contrastive%20BiLSTM-enabled%20Health%20Representation%20Learning%20for%20Remaining%20Useful%20Life%20Prediction/" class="post-title-link" itemprop="url">Contrastive BiLSTM-enabled Health Representation Learning for Remaining Useful Life Prediction</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-06 14:01:07" itemprop="dateCreated datePublished" datetime="2024-06-06T14:01:07+08:00">2024-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-05-29 20:34:40" itemprop="dateModified" datetime="2024-05-29T20:34:40+08:00">2024-05-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/paper-note/" itemprop="url" rel="index"><span itemprop="name">paper note</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><strong>2023.12 西安交通大学 8.1 1区 Reliability Engineering &amp; System Safety</strong></p>
<h2 id="1-abstract"><a href="#1-abstract" class="headerlink" title="1.abstract"></a>1.abstract</h2><p>many existing deep learning approaches overlook the inherent ordered relationship between samples in the direct mapping from sliced data to RUL pattern. To capture the faithful and ordered health representation of a given system, a Contrastive Bidirectional LSTM-enabled Health Representation Learning (CBHRL) framework is proposed.</p>
<h2 id="2-contributions"><a href="#2-contributions" class="headerlink" title="2.contributions"></a>2.contributions</h2><ol>
<li>A contrastive BiLSTM-enabled health representation learning framework is proposed. CBHRL ranks the similarity between different samples through supervised contrastive regression loss to construct a more monotonic, smooth and trended health representation, which is beneficial to improve the prediction performance.</li>
<li>To construct the multi-view of degradation data, the series odd-even decomposition (SOED) method is proposed. The proposed data augmentation method can construct two degradation series which share mutual information but distinguish with each other. Additionally, this approach proves beneficial in enhancing the model’s generalization ability and prediction accuracy.</li>
<li>The regression prediction method exhibits more accurately during the majority of lifetime in degradation, while the similarity prediction method shows superior performance in serval cycles before failure and better interpretability.</li>
</ol>
<h2 id="3-proposed-method"><a href="#3-proposed-method" class="headerlink" title="3.proposed method"></a>3.proposed method</h2><p>The SOED is designed to construct multi-view degradation series, enhancing the contrastive learning ability. In health representation learning, the supervised contrastive regression loss is used to optimize the encoder. The supervised contrastive regression loss forces the encoder to extract the continuous health representation.</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/66571badd9c307b7e9475cad.png" >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/66571badd9c307b7e9475ce6.png" >
</div>

<h3 id="Supervised-Contrastive-Regression-Loss"><a href="#Supervised-Contrastive-Regression-Loss" class="headerlink" title="Supervised Contrastive Regression Loss"></a>Supervised Contrastive Regression Loss</h3><div align=center>
<img src="https://pic.imgdb.cn/item/66571badd9c307b7e9475d40.png" >
</div>

<h3 id="Series-Odd-Even-Decomposition"><a href="#Series-Odd-Even-Decomposition" class="headerlink" title="Series Odd-Even Decomposition"></a>Series Odd-Even Decomposition</h3><div align=center>
<img src="https://pic.imgdb.cn/item/66571baed9c307b7e9475da5.png" >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/66571be5d9c307b7e94795f1.png" >
</div>

<p>Good multi-view data are expected to have certain mutual information and distinguish with each other. The most common method to build multi-view data is data augmentation. However, the common series data augmentation method is not suitable for degradation series. The common series augmentations method such as warping, flipping will not consider how to keep the tendency of degradation, while other methods such as noise injection is unable to provide adequate differences.</p>
<p><strong>The two sub-series keep part of the detail information and the tendency of the degradation. To remain the sequence length, the linear interpolation is used to fill two sub-series to return the original sequence length.</strong></p>
<h3 id="RUL-Prediction-Method"><a href="#RUL-Prediction-Method" class="headerlink" title="RUL Prediction Method"></a>RUL Prediction Method</h3><div align=center>
<img src="https://pic.imgdb.cn/item/66571be5d9c307b7e94795a8.png" >
</div>

<h2 id="4-Experimental-Study"><a href="#4-Experimental-Study" class="headerlink" title="4. Experimental Study"></a>4. Experimental Study</h2><h3 id="4-1-Case-1-C-MAPSS-dataset"><a href="#4-1-Case-1-C-MAPSS-dataset" class="headerlink" title="4.1. Case 1: C-MAPSS dataset"></a>4.1. Case 1: C-MAPSS dataset</h3><h4 id="Experiment-setup"><a href="#Experiment-setup" class="headerlink" title="Experiment setup"></a>Experiment setup</h4><p>For FD002 and FD004, the SOED is not applied since the degradation tendency is disordered by multi-operating conditions. To generate the sequence samples, the time window sliding method is employed. At each time step, all historical sensor data within time window are collected to create a high-dimensional feature vector, and used as the input for the encoder. In this study, the time window size keeps constant 30 for all sub-datasets.</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/66571df1d9c307b7e949a4b2.png" >
</div>

<h4 id="Health-representation-analysis"><a href="#Health-representation-analysis" class="headerlink" title="Health representation analysis"></a>Health representation analysis</h4><div align=center>
<img src="https://pic.imgdb.cn/item/66571df1d9c307b7e949a449.png" >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/66571df1d9c307b7e949a3ff.png" >
</div>

<h4 id="Comparative-study-of-SOED"><a href="#Comparative-study-of-SOED" class="headerlink" title="Comparative study of SOED"></a>Comparative study of SOED</h4><div align=center>
<img src="https://pic.imgdb.cn/item/66571df1d9c307b7e949a3c2.png" >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/66571df1d9c307b7e949a395.png" >
</div>

<h4 id="Effectiveness-of-CBHRL"><a href="#Effectiveness-of-CBHRL" class="headerlink" title="Effectiveness of CBHRL"></a>Effectiveness of CBHRL</h4><div align=center>
<img src="https://pic.imgdb.cn/item/66571d9bd9c307b7e9494fef.png" >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/66571d9bd9c307b7e9494fd1.png" >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/66571d9ad9c307b7e9494f9c.png" >
</div>

<h3 id="4-2-Case-2-PRONOSTIA-dataset"><a href="#4-2-Case-2-PRONOSTIA-dataset" class="headerlink" title="4.2. Case 2: PRONOSTIA dataset"></a>4.2. Case 2: PRONOSTIA dataset</h3><h4 id="Implement-details"><a href="#Implement-details" class="headerlink" title="Implement details"></a>Implement details</h4><p>Therefore, twelve features are extracted from horizontal vibration signals as suggested in [33]. Specifically, serval statistical indicators are extracted from both time and frequency domain. Regarding time-frequency domain, energy ratios are calculated through wavelet package decomposition with three-level Daubechies 4 and 4 sub-bands’ energy ratios are selected as features.</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/66571d9ad9c307b7e9494f82.png" >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/66571d9ad9c307b7e9494f32.png" >
</div>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://edmund199.github.io.git/2024/06/06/paper-note/RUL/transformer/Variational%20encoding%20approach%20for%20interpretable%20assessment%20of%20remaining%20useful%20life%20estimation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="edmund">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | null">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/06/paper-note/RUL/transformer/Variational%20encoding%20approach%20for%20interpretable%20assessment%20of%20remaining%20useful%20life%20estimation/" class="post-title-link" itemprop="url">Variational encoding approach for interpretable assessment of remaining useful life estimation</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-06 14:01:07" itemprop="dateCreated datePublished" datetime="2024-06-06T14:01:07+08:00">2024-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-01-16 09:38:38" itemprop="dateModified" datetime="2024-01-16T09:38:38+08:00">2024-01-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/paper-note/" itemprop="url" rel="index"><span itemprop="name">paper note</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Variational-encoding-approach-for-interpretable-assessment-of-remaining-useful-life-estimation"><a href="#Variational-encoding-approach-for-interpretable-assessment-of-remaining-useful-life-estimation" class="headerlink" title="Variational encoding approach for interpretable assessment of remaining useful life estimation"></a>Variational encoding approach for interpretable assessment of remaining useful life estimation</h2><p><strong>2022.1 西班牙 8.1 1区 Reliability Engineering &amp; System Safety</strong></p>
<h3 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h3><p><strong>most of them lack an explanatory component to understand model learning and/or the nature of the data. To overcome this gap we propose a novel approach based on variational encoding.</strong>The model consists of a recurrent encoder and a regression model: the encoder learns to compress the input data to a latent space that serves as a basis to build a self-explanatory map that can visually evaluate the rate of deterioration of aircraft engines. <strong>Obtaining such a latent space is regularized by a new cost function guided by variational inference and a term that penalizes prediction errors.</strong></p>
<h3 id="1introduction"><a href="#1introduction" class="headerlink" title="1introduction"></a>1introduction</h3><ul>
<li>model-based and data-driven approaches </li>
<li>the use of machine learing models</li>
<li>the use of cnn and rnn(there is a clear gap between all Deep Learning oriented approaches: although they do achieve remarkable results, models are treated as black boxes where inputs are used to obtain some output) </li>
<li>To meet the goals stated one can think of unsupervised learning techniques as a possible way to approach this. Especially, when it comes to reveal insights about the nature of the data, Representation Learning approaches such as autoencoders come in handy</li>
<li>Variational Autoencoders (VAEs).(In VAEs, variational inference is added to the error function through the Kullback–Leibler term, which guarantees that data with similar patterns will also be encoded nearby in the latent space. VAEs are a recent but well-known alternative with numerous applications in anomaly analysis)</li>
<li>This problem has many points in common with the diagnosis of anomalies and has also been solved by using autoencoders [36,37]. Despite these similarities, both problems have a fundamental difference: in anomaly diagnosis, the aim is to look for individuals in unlikely areas of the latent space. In RUL prediction, on the contrary, the objective for a complete and interpretable diagnosis should be to project the evolution of the system in the latent space</li>
</ul>
<h3 id="2preliminary"><a href="#2preliminary" class="headerlink" title="2preliminary"></a>2preliminary</h3><p>2.1 piece-wise RUL</p>
<p>2.2 metric<br>RMSE and Score</p>
<h3 id="3model"><a href="#3model" class="headerlink" title="3model"></a>3model</h3><h4 id="3-1model1"><a href="#3-1model1" class="headerlink" title="3.1model1"></a>3.1model1</h4><p>The proposed model consists of three components: an encoder network, a regression model and a latent space.<br><strong>encode:</strong><br> The encoder learns to compress the data into the latent space so that it is described by the parameters that initialize the probability distribution to which the data belongs. Variational inference is added to the loss function through the <strong>Kullback–Leibler divergence, which measures how much one probability distribution diverges from another, to learn the abovementioned parameters. A second term is also added to penalize wrong estimations of the regression model.</strong><br>Thereby, the main difference with respect to a VAE is that we replace the decoder with a regression model, as shown in Fig. 3, and the training is done differently.</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65a5de07871b83018a2c1688.png" >
</div>

<p><strong>regression</strong><br>Among the different types of RNNs that can be found, LSTM networks are the most popular. These networks process data from backward to forward conserving information from the past through hidden states. However,<br>Bidirectional LSTM networks are in high demand because they provide not only information about the past but also about the future: data is first processed from past to future and then from future to past, thus preserving the information from both periods.</p>
<h4 id="3-2-Interpretable-diagnosis"><a href="#3-2-Interpretable-diagnosis" class="headerlink" title="3.2. Interpretable diagnosis"></a>3.2. Interpretable diagnosis</h4><p>The diagnostic tool introduced in this work is a map that shows the actual state of the engine and also the rate of change from healthy to deteriorated</p>
<h3 id="4-Experimental-design"><a href="#4-Experimental-design" class="headerlink" title="4. Experimental design"></a>4. Experimental design</h3><p>preprocess:<br>With this approach, all records of the same operating condition are grouped together and scaled using a standard scaler.(工况标准化)</p>
<p>On the other hand, although sensor data have a general trend, it is known that they are subject to local oscillations, mainly caused by highfrequency sensors, which lead to noise [23,43]. To ease the processing of the series, an exponential weighted moving average is carried out.（输入指数平滑）</p>
<p>In time series problems it is quite recurrent to split the data into sequences for better prediction performance.In those cases a masked value is used and will be treated in the first layer of the model by simply ignoring those values. In this way, as much information as possible is used.（time window）</p>
<p><strong>along with the use of the Hyperopt Bayesian optimization library（hyperparameter 确定）</strong></p>
<p><strong>The choice of the sensors is not arbitrary, we only use the following six: T30, T50, P30, EPRA, PS30 and phi。Moreover, for datasets FD001 and FD003 the EPRA sensor is not necessary since it measures the engine thrust under different operating conditions while FD001 and FD003 operate under the same condition</strong></p>
<h3 id="5-Experimental-results"><a href="#5-Experimental-results" class="headerlink" title="5. Experimental results"></a>5. Experimental results</h3><p>bold. It can be quickly noted that with datasets FD001 and FD003, although the metrics are considered good, they are not the best. However, the interest lies mostly in FD002 and FD004 as the increasing number of operating conditions and failure modes make these two datasets contain more complicated multiscale degradation features.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://edmund199.github.io.git/2024/06/06/paper-note/RUL/transformer/Dual-Aspect%20Self-Attention%20Based%20on%20Transformer%20for%20Remaining%20Useful%20Life%20Prediction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="edmund">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | null">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/06/paper-note/RUL/transformer/Dual-Aspect%20Self-Attention%20Based%20on%20Transformer%20for%20Remaining%20Useful%20Life%20Prediction/" class="post-title-link" itemprop="url">Dual-Aspect Self-Attention Based on Transformer for Remaining Useful Life Prediction</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-06 14:01:07" itemprop="dateCreated datePublished" datetime="2024-06-06T14:01:07+08:00">2024-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-01-16 09:38:01" itemprop="dateModified" datetime="2024-01-16T09:38:01+08:00">2024-01-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/paper-note/" itemprop="url" rel="index"><span itemprop="name">paper note</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Dual-Aspect-Self-Attention-Based-on-Transformer-for-Remaining-Useful-Life-Prediction"><a href="#Dual-Aspect-Self-Attention-Based-on-Transformer-for-Remaining-Useful-Life-Prediction" class="headerlink" title="Dual-Aspect Self-Attention Based on Transformer for Remaining Useful Life Prediction"></a>Dual-Aspect Self-Attention Based on Transformer for Remaining Useful Life Prediction</h2><p><strong>2022.12 电子科技大学  arxiv</strong></p>
<h3 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h3><p>With the widespread deployment of sensors on industrial equipment, building the Industrial Internet of Things (IIoT) to interconnect these devices has become an inexorable trend in the development of the digital factory.<br>介绍了IIOT</p>
<p>We investigated the mainstream RUL prediction models and summarized the basic steps of RUL prediction modeling in this scenario. On this basis, a data-driven approach for RUL estimation is proposed in this paper.<br>介绍方法</p>
<h3 id="1introduction"><a href="#1introduction" class="headerlink" title="1introduction"></a>1introduction</h3><p>The emergence of low-cost micro-sensors and high-bandwidth wireless networks enables real-time access to machine data. Big data and AI extract valuable insights, enhancing productivity and reducing failure risks. This has led to the rise of Industrial Internet of Things (IIoT), transforming data into a critical resource. A key IIoT application involves using big data for predictive maintenance of complex machinery.</p>
<p>RUL estimation algorithm is the core algorithms for predictive maintenance and PHM systems.</p>
<p>In recent years, data-driven RUL prediction algorithms have received increasing attention.</p>
<p>Traditional machine learning algorithms (such as SVM[11], ANN[12], and DBN[13]) have achieved good results in RUL prediction.</p>
<p><strong>However, these networks all treat the time series of multiple sensors equally, but in fact, different sensors have different contributions to theRUL values.According to where the attention mechanisms are used, they are divided into three types: time weighting, feature (sensor) weighting, and two dimensions weighting together.Furthermore, the basic attention mechanism cannot model the intrinsic connection of features.</strong><br>上述方法中没有考虑不同传感器的重要程度，而对于注意力机制有time weighting和feature weighting and two dimensions weighting together，而传统的注意力机制没有考虑特征的内在联系。</p>
<p>the self-attention mechanism does not require external information and is better at capturing the internal correlations of features. Additionally, the multi-head attention mechanism uses the attention weights of multiple dimensions to aggregate different contributions of features from multiple perspectives.</p>
<h3 id="2preliminary"><a href="#2preliminary" class="headerlink" title="2preliminary"></a>2preliminary</h3><h3 id="2-1-Multi-head-Attention"><a href="#2-1-Multi-head-Attention" class="headerlink" title="2.1 Multi-head Attention"></a>2.1 Multi-head Attention</h3><p>Polosukhin, Attention is all you need (2017）</p>
<h3 id="2-2-proposed-methond"><a href="#2-2-proposed-methond" class="headerlink" title="2.2 proposed methond"></a>2.2 proposed methond</h3><div align=center>
<img src="https://pic.imgdb.cn/item/65a5dd6d871b83018a2add19.png" >
</div>

<h3 id="3-Experiment-Setting"><a href="#3-Experiment-Setting" class="headerlink" title="3. Experiment Setting"></a>3. Experiment Setting</h3><h4 id="3-1DATAset"><a href="#3-1DATAset" class="headerlink" title="3.1DATAset"></a>3.1DATAset</h4><p>CMAPSS dataset</p>
<h4 id="3-2-Data-Pre——Processing"><a href="#3-2-Data-Pre——Processing" class="headerlink" title="3.2 Data Pre——Processing"></a>3.2 Data Pre——Processing</h4><p><strong>piece-wise RUL</strong></p>
<p>refer：<br>Sun, Remaining useful life estimation in prognostics using deep convolution neural networks, Reliability Engineering &amp; System Safety 172 (2018) 1–11</p>
<p>Li, Machine remaining useful life prediction via an attention-based deep learning approach, IEEE Transactions on Industrial Electronics 68 (3) (2021) 2521–2531</p>
<p><strong>cluster and normalization</strong></p>
<p>In the absence of prior expertise, reasonable max-min values for sensors are difficult to determine, so we use z-score normalization,</p>
<p>why norm by cluster：<br>Figure 7.c) illustrates the data colored by working conditions, and 7.d) is the data normalized separately by working conditions, which shows that the data trend with the time step is distinct from the unnormalized data.</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65a5dd6e871b83018a2adda1.png" >
</div>

<p><strong>time window</strong></p>
<p>sliding_size=T step=1</p>
<p>对于序列长度小于time window的用第一个数据值对数据pad</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># row number &lt; sequence length, only one sequence</span></span><br><span class="line"><span class="comment"># pad width first time-cycle value</span></span><br><span class="line">all_array.append(np.pad(id_array, ((seq_len - id_array.shape[<span class="number">0</span>], <span class="number">0</span>), (<span class="number">0</span>, <span class="number">0</span>)), <span class="string">&#x27;edge&#x27;</span>))</span><br></pre></td></tr></table></figure>
<h4 id="3-3-setup"><a href="#3-3-setup" class="headerlink" title="3.3 setup"></a>3.3 setup</h4><p><strong>metric</strong></p>
<p>RMSE and score</p>
<p><strong>hyper parameters</strong></p>
<p>T=30<br>use all sensor feature</p>
<p>The Adam[44] algorithm was applied to optimize the proposed model. The learning rate of Adam was set to 0.0002. The number of training batches was set to 128, and the early stop mechanism was employed to stop training after 50 rounds without better results. For the proposed model, the LSTM uses three hidden layers with 100 nodes per layer. The MLP layer has a hidden layer with 100 nodes, the activation function is ReLU[45], and the dropout is set to 0.5. The final output layer uses a single node to predict the RUL value.</p>
<h3 id="4-result-analysis"><a href="#4-result-analysis" class="headerlink" title="4 result analysis"></a>4 result analysis</h3><h4 id="4-1-parameter-study"><a href="#4-1-parameter-study" class="headerlink" title="4.1 parameter study"></a>4.1 parameter study</h4><p><strong>feature head</strong></p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65a5dd6e871b83018a2addea.png" >
</div>

<p><strong>time head</strong></p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65a5dd6e871b83018a2ade24.png" >
</div>

<p><strong>Impact of RNN Cell</strong></p>
<p>RNN and GRU：Among them, RNN has the worst performance, followed by GRU. Meanwhile, the repeated trials of these two models are not as stable as others.</p>
<p>Bi-LSTM performs better than GRU but worse than LSTM because the bidirectional LSTM increases the model complexity. Further, the Bi-LSTM is intended to infer the following content through the bidirectional relationship of the sequences. In contrast, the signal sequence of the sensor in the RUL estimation scenario is meaningless when reversed. Therefore BiLSTM did not achieve the desired results.</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65a5dd6e871b83018a2ade73.png" >
</div>

<p><strong>Impact of Window Size</strong></p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65a5ddb6871b83018a2b7810.png" >
</div>

<p><strong>Impact of Piece-Wise RUL</strong></p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65a5ddb6871b83018a2b787a.png" >
</div>

<h4 id="4-2-ablation-study"><a href="#4-2-ablation-study" class="headerlink" title="4.2 ablation study"></a>4.2 ablation study</h4><p>Where L denotes the single LSTM network, A denotes the single head attention mechanism on features, F denotes using only multi-head attention on features, and F + T denotes using multi-head attention both on features and sequences.</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65a5ddb6871b83018a2b78db.png" >
</div>


<h4 id="4-3-Attention-Scheme-Study"><a href="#4-3-Attention-Scheme-Study" class="headerlink" title="4.3 Attention Scheme Study"></a>4.3 Attention Scheme Study</h4><p>Where P is the proposed model; F and S are basic attention weighted in feature and time dimension, respectively; F+S represents first weighted by features and then weighted by time.</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/65a5ddb7871b83018a2b7939.png" >
</div>

<h4 id="4-4Case-Study"><a href="#4-4Case-Study" class="headerlink" title="4.4Case Study"></a>4.4Case Study</h4><h4 id="4-5-Interpretability-of-Attention"><a href="#4-5-Interpretability-of-Attention" class="headerlink" title="4.5. Interpretability of Attention"></a>4.5. Interpretability of Attention</h4><h4 id="4-6-Comparison-with-other-work"><a href="#4-6-Comparison-with-other-work" class="headerlink" title="4.6. Comparison with other work"></a>4.6. Comparison with other work</h4><p>Results on C-MAPSS</p>
<p>Results on PHM08</p>
<h3 id="5-Conclution"><a href="#5-Conclution" class="headerlink" title="5 Conclution"></a>5 Conclution</h3>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://edmund199.github.io.git/2024/06/06/paper-note/RUL/Remaining%20useful%20life%20estimation%20via%20transformer%20encoder%20enhanced%20by%20a%20gated%20convolutional%20unit/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="edmund">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | null">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/06/paper-note/RUL/Remaining%20useful%20life%20estimation%20via%20transformer%20encoder%20enhanced%20by%20a%20gated%20convolutional%20unit/" class="post-title-link" itemprop="url">Remaining useful life estimation via transformer encoder enhanced by a gated convolutional unit</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-06 14:01:07" itemprop="dateCreated datePublished" datetime="2024-06-06T14:01:07+08:00">2024-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-11-26 22:01:33" itemprop="dateModified" datetime="2023-11-26T22:01:33+08:00">2023-11-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/paper-note/" itemprop="url" rel="index"><span itemprop="name">paper note</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Remaining-useful-life-estimation-via-transformer-encoder-enhanced-by-a-gated-convolutional-unit"><a href="#Remaining-useful-life-estimation-via-transformer-encoder-enhanced-by-a-gated-convolutional-unit" class="headerlink" title="Remaining useful life estimation via transformer encoder enhanced by a gated convolutional unit"></a>Remaining useful life estimation via transformer encoder enhanced by a gated convolutional unit</h2><h3 id="Journal-of-Intelligent-Manufacturing-8-3-1区"><a href="#Journal-of-Intelligent-Manufacturing-8-3-1区" class="headerlink" title="Journal of Intelligent Manufacturing 8.3 1区"></a>Journal of Intelligent Manufacturing 8.3 1区</h3><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>使用的数据：C-MAPSS数据集。<br>创新点：论文使用了基于深度神经网络的新方法，采用了Transformer编码器作为模型主体，并结合点积自注意力机制和门控卷积单元，以捕捉时间序列中的短期和长期依赖关系。与传统的卷积神经网络和循环神经网络方法相比，该模型克服了核大小和顺序依赖性的限制，同时充分利用了并行计算的优势。在实验中，该模型在C-MAPSS数据集上展现出优于或与其他现有方法相当的性能，同时通过消融研究证明了所使用组件的必要性和有效性。</p>
<h2 id="论文结构"><a href="#论文结构" class="headerlink" title="论文结构"></a>论文结构</h2><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>该部分介绍了剩余寿命（RUL）估计的研究背景和传统基于物理模型和数据驱动模型的方法。</p>
<h3 id="related-work"><a href="#related-work" class="headerlink" title="related work"></a>related work</h3><p>introduces the related work on RUL estimation and backbone of the proposed method </p>
<p>Deep learning based RUL estimation</p>
<p>Transformer architecture</p>
<h3 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h3><p>describe the proposed model structure</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/655caee7c458853aef2fc757.png" >
</div>

<h4 id="1-Encoder-Layer"><a href="#1-Encoder-Layer" class="headerlink" title="1.Encoder Layer"></a>1.Encoder Layer</h4><h5 id="Multi-head-attention"><a href="#Multi-head-attention" class="headerlink" title="Multi-head attention"></a>Multi-head attention</h5><p>重点是把q，k，v分成H份，移到前面的维度。使计算权重系数a时为每个头分别计算。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHeadAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, heads, d_model, dropout=<span class="number">0.5</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.d_model = d_model</span><br><span class="line">        self.d_k = d_model // heads</span><br><span class="line">        self.h = heads</span><br><span class="line"></span><br><span class="line">        self.q_linear = nn.Linear(d_model, d_model)</span><br><span class="line">        self.v_linear = nn.Linear(d_model, d_model)</span><br><span class="line">        self.k_linear = nn.Linear(d_model, d_model)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line">        self.out = nn.Linear(d_model, d_model)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, q, k, v, mask=<span class="literal">None</span></span>):</span><br><span class="line">        bs = q.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># perform linear operation and split into h heads</span></span><br><span class="line"></span><br><span class="line">        k = self.k_linear(k).view(bs, -<span class="number">1</span>, self.h, self.d_k)</span><br><span class="line">        q = self.q_linear(q).view(bs, -<span class="number">1</span>, self.h, self.d_k)</span><br><span class="line">        v = self.v_linear(v).view(bs, -<span class="number">1</span>, self.h, self.d_k)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># transpose to get dimensions bs * h * sl * d_model</span></span><br><span class="line"></span><br><span class="line">        k = k.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        q = q.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        v = v.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># calculate attention using function we will define next</span></span><br><span class="line">        scores = attention(q, k, v, self.d_k, mask, self.dropout)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># concatenate heads and put through final linear layer</span></span><br><span class="line">        concat = scores.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous() \</span><br><span class="line">            .view(bs, -<span class="number">1</span>, self.d_model)</span><br><span class="line">        <span class="comment"># scores.trabspose().contiguous() 使scores不会被改变</span></span><br><span class="line">        output = self.out(concat)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">attention</span>(<span class="params">q, k, v, d_k, mask=<span class="literal">None</span>, dropout=<span class="literal">None</span></span>):</span><br><span class="line">    scores = torch.matmul(q, k.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) / math.sqrt(d_k)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        mask = mask.unsqueeze(<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># scores = scores.masked_fill(mask == 0, -1e9)</span></span><br><span class="line">    scores = F.softmax(scores, dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> dropout <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        scores = dropout(scores)</span><br><span class="line"></span><br><span class="line">    output = torch.matmul(scores, v)</span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<h5 id="Feed-forward-network"><a href="#Feed-forward-network" class="headerlink" title="Feed forward network"></a>Feed forward network</h5><p>FC</p>
<h4 id="2-Local-featrue-extraction-layer"><a href="#2-Local-featrue-extraction-layer" class="headerlink" title="2.Local featrue extraction layer"></a>2.Local featrue extraction layer</h4><h5 id="Convolution"><a href="#Convolution" class="headerlink" title="Convolution"></a>Convolution</h5><p>Conv2d</p>
<h5 id="Gating-mechanism"><a href="#Gating-mechanism" class="headerlink" title="Gating mechanism"></a>Gating mechanism</h5><h5 id="Liner-mapping"><a href="#Liner-mapping" class="headerlink" title="Liner mapping"></a>Liner mapping</h5><h5 id="Position-Encoding"><a href="#Position-Encoding" class="headerlink" title="Position Encoding"></a>Position Encoding</h5><div align=center>
<img src="https://pic.imgdb.cn/item/655caee7c458853aef2fc660.png" >
</div>


<h4 id="3-Regression-layer"><a href="#3-Regression-layer" class="headerlink" title="3.Regression layer"></a>3.Regression layer</h4><h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3><h4 id="settings"><a href="#settings" class="headerlink" title="settings"></a>settings</h4><h5 id="Benchmark-Datasets："><a href="#Benchmark-Datasets：" class="headerlink" title="Benchmark Datasets："></a>Benchmark Datasets：</h5><p>C-MAPSS</p>
<h5 id="Data-pre-processing："><a href="#Data-pre-processing：" class="headerlink" title="Data pre-processing："></a>Data pre-processing：</h5><p><strong><em>sensor selection</em></strong><br>More specifically, the monotonicity matrix and correlation matrix are used for sensor selection. The monotonicity matrix represents the tendency of features along the time dimension, the feature dimensions with monotonicity contain more abundant degeneration information. The correlation matrix reflects the relationship between feature dimension and operation time.<br>reason:数据集共有26个传感器，但不是所以传感器都有与RUL相关的信息，因此根据论文[1]进行传感器选择。主要计算相关性矩阵和单调矩阵（？）</p>
<p><strong><em>Normalization</em></strong><br>min-max normalization</p>
<p><strong><em>Piece-wise RUL</em></strong><br>we first label RULs at the beginning with a constant RU Lmax, i.e., the horizon dot line. After running for a period of time, the system begins to enter a phase of linear degradation until it fails.<br>reason:the system degradation is negligible at the early stage of its life cycle</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/655caee7c458853aef2fc7f1.png" >
</div>

<h5 id="Implementation-details"><a href="#Implementation-details" class="headerlink" title="Implementation details"></a>Implementation details</h5><p>参数设置</p>
<h5 id="Evaluation-metric"><a href="#Evaluation-metric" class="headerlink" title="Evaluation metric"></a>Evaluation metric</h5><p>RMSE</p>
<h4 id="Performers-comparison"><a href="#Performers-comparison" class="headerlink" title="Performers comparison"></a>Performers comparison</h4><h4 id="Ablation-study"><a href="#Ablation-study" class="headerlink" title="Ablation study"></a>Ablation study</h4><p>1.w/o GCU<br>2.w/o GCU w/o sigmoid</p>
<h3 id="conclusion"><a href="#conclusion" class="headerlink" title="conclusion"></a>conclusion</h3><h2 id="code"><a href="#code" class="headerlink" title="code"></a>code</h2><blockquote>
<p>baseline only for FD001<br>( <a target="_blank" rel="noopener" href="https://github.com/jiaxiang-cheng/PyTorch-Transformer-for-RUL-Prediction">https://github.com/jiaxiang-cheng/PyTorch-Transformer-for-RUL-Prediction</a>)</p>
<p>more complicate realize<br>(<a target="_blank" rel="noopener" href="https://github.com/GuoHaoren/Implementation-of-GCU-Transformer-for-RUL-Prediction-on-CMAPSS">https://github.com/GuoHaoren/Implementation-of-GCU-Transformer-for-RUL-Prediction-on-CMAPSS</a>)</p>
</blockquote>
<p>[1]:Wu, Q., Ding, K., &amp; Huang, B. (2018). Approach for fault prognosis using recurrent neural network. Journal of Intelligent Manufacturing, 1–13.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">edmund</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  




  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
