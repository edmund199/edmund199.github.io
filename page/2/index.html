<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.1.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"edmund199.github.io.git","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title">
<meta property="og:url" content="https://edmund199.github.io.git/page/2/index.html">
<meta property="og:site_name">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="edmund">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://edmund199.github.io.git/page/2/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/2/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title></title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title"></h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">edmund</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">30</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://edmund199.github.io.git/2024/06/06/paper-note/RUL/Remaining%20Useful%20Life%20(RUL)%20Prediction%20of%20Mechanical%20Bearings%20Using%20Convolution%20Neural%20Network%20(CNN)%20and%20Long%20Short%20Term%20Memory%20(LSTM)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="edmund">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | null">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/06/paper-note/RUL/Remaining%20Useful%20Life%20(RUL)%20Prediction%20of%20Mechanical%20Bearings%20Using%20Convolution%20Neural%20Network%20(CNN)%20and%20Long%20Short%20Term%20Memory%20(LSTM)/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-06 14:01:07" itemprop="dateCreated datePublished" datetime="2024-06-06T14:01:07+08:00">2024-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-29 11:25:39" itemprop="dateModified" datetime="2024-02-29T11:25:39+08:00">2024-02-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/paper-note/" itemprop="url" rel="index"><span itemprop="name">paper note</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Remaining-Useful-Life-RUL-Prediction-of-Mechanical-Bearings-Using-Convolution-Neural-Network-CNN-and-Long-Short-Term-Memory-LSTM"><a href="#Remaining-Useful-Life-RUL-Prediction-of-Mechanical-Bearings-Using-Convolution-Neural-Network-CNN-and-Long-Short-Term-Memory-LSTM" class="headerlink" title="Remaining Useful Life (RUL) Prediction of Mechanical Bearings Using Convolution Neural Network (CNN) and Long Short Term Memory (LSTM)"></a>Remaining Useful Life (RUL) Prediction of Mechanical Bearings Using Convolution Neural Network (CNN) and Long Short Term Memory (LSTM)</h2><p><strong>high technology letters</strong></p>
<h3 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h3><p>In this article, PRONOSTIA Dataset for Bearings(PHM IEEE 2012 Data Challenge Dataset) is used. For every 10 seconds, vibration signals are recorded for 0.1 seconds in the dataset. The recorded signals are 1D raw vibration signals(Time-Domain). The 1D signals are difﬁcult to analyze, so 1D vibration signals are transformed into the 2D image-like features(Time and Frequency-Domain) using CWT(Continuous Wavelet Transform). And CNN(Convolution Neural Network) + LSTM(Long Short-Term Memory) is applied to the acquired features from CWT to calculate the HI. The calculated HI is then used for RUL Prediction.</p>
<h3 id="keys"><a href="#keys" class="headerlink" title="keys"></a>keys</h3><p>We employed Data Normalization technique after applying CWT to the 1D collected data to normalize the coefﬁcients of 2D CWT data. To achieve Data Normalization we performed Data Re-scaling method A.K.A min max normalization to re-scale or adjust all the 2D data</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">WIN_SIZE=<span class="number">20</span></span><br><span class="line">DATA_POINTS_PRE_FILE=<span class="number">2560</span></span><br><span class="line">WAVELET_TYPE=<span class="string">&#x27;morl&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_feature_image</span>(<span class="params">ind, feature_name=<span class="string">&#x27;horiz accel&#x27;</span></span>):</span><br><span class="line">    data_range = df_row_ind_to_data_range(ind)</span><br><span class="line">    data = df[feature_name].values[data_range[<span class="number">0</span>]:data_range[<span class="number">1</span>]]</span><br><span class="line">    <span class="comment"># use window to process(= prepare, develop) 1D signal</span></span><br><span class="line">    data = np.array([np.mean(data[i:i+WIN_SIZE]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, DATA_POINTS_PER_FILE, WIN_SIZE)])</span><br><span class="line">    <span class="comment">#data (128,1)</span></span><br><span class="line">    <span class="comment"># perform CWT on 1D data(= 1D array)</span></span><br><span class="line">    coef, _ = pywt.cwt(data, np.linspace(<span class="number">1</span>,<span class="number">128</span>,<span class="number">128</span>), WAVELET_TYPE)</span><br><span class="line">    <span class="comment">#coef (128,128)</span></span><br><span class="line">    <span class="comment"># transform to power and apply logarithm?!</span></span><br><span class="line">    coef = np.log2(coef**<span class="number">2</span>+<span class="number">0.001</span>)</span><br><span class="line">    <span class="comment"># normalize coef</span></span><br><span class="line">    coef = (coef - coef.<span class="built_in">min</span>())/(coef.<span class="built_in">max</span>() - coef.<span class="built_in">min</span>()) </span><br><span class="line">    <span class="keyword">return</span> coef</span><br></pre></td></tr></table></figure>
<ul>
<li>for bearing1_1 the data finally be (2803, 2, 128, 128)</li>
<li>the scale of cwt decide the size of coef which also means the scale of the wavelet</li>
</ul>
<p>todo</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://edmund199.github.io.git/2024/06/06/paper-note/RUL/layout/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="edmund">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | null">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/06/paper-note/RUL/layout/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-06 14:01:07" itemprop="dateCreated datePublished" datetime="2024-06-06T14:01:07+08:00">2024-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-12-17 21:43:05" itemprop="dateModified" datetime="2023-12-17T21:43:05+08:00">2023-12-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/paper-note/" itemprop="url" rel="index"><span itemprop="name">paper note</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id=""><a href="#" class="headerlink" title=" "></a> </h2><p><strong>2021 西安交通大学 8.1 1区 Reliability Engineering &amp; System Safety</strong></p>
<h3 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h3><h3 id="1introduction"><a href="#1introduction" class="headerlink" title="1introduction"></a>1introduction</h3><h3 id="2preliminary"><a href="#2preliminary" class="headerlink" title="2preliminary"></a>2preliminary</h3><div align=center>
<img src="" >
</div>








      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://edmund199.github.io.git/2024/06/06/paper-note/RUL/Hierarchical%20attention%20graph%20convolutional%20network%20to%20fuse%20multi-sensor%20signals%20for%20remaining%20useful%20life%20prediction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="edmund">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | null">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/06/paper-note/RUL/Hierarchical%20attention%20graph%20convolutional%20network%20to%20fuse%20multi-sensor%20signals%20for%20remaining%20useful%20life%20prediction/" class="post-title-link" itemprop="url">Hierarchical attention graph convolutional network to fuse multi-sensor signals for remaining useful life prediction</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-06 14:01:07" itemprop="dateCreated datePublished" datetime="2024-06-06T14:01:07+08:00">2024-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-12-16 21:38:58" itemprop="dateModified" datetime="2023-12-16T21:38:58+08:00">2023-12-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/paper-note/" itemprop="url" rel="index"><span itemprop="name">paper note</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Hierarchical-attention-graph-convolutional-network-to-fuse-multi-sensor-signals-for-remaining-useful-life-prediction"><a href="#Hierarchical-attention-graph-convolutional-network-to-fuse-multi-sensor-signals-for-remaining-useful-life-prediction" class="headerlink" title="Hierarchical attention graph convolutional network to fuse multi-sensor signals for remaining useful life prediction"></a>Hierarchical attention graph convolutional network to fuse multi-sensor signals for remaining useful life prediction</h2><p><strong>2021 西安交通大学 8.1 1区 Reliability Engineering &amp; System Safety</strong></p>
<h3 id="1abstract"><a href="#1abstract" class="headerlink" title="1abstract"></a>1abstract</h3><p>1.过去方法的缺陷：1）传感器间的联系为被考虑。2）更注重对传感器时间依赖性的建模，而忽略空间依赖性。<br>2.文章提出的Hierarchical attention graph convolutional network(HAGCN),包含对spatial dependencies建模的<em>the hierarchical graph representation layer</em>和对tenporal dependencies建模的 <em>bi-directional long short-term memory network</em><br>此外还设计了 <em>regularized self-attention graph pooling</em>对传感器信息的融合</p>
<h3 id="2introduction"><a href="#2introduction" class="headerlink" title="2introduction"></a>2introduction</h3><p>PHM<br>model-driven and data-driven<br>ML and DL in data-driven<br>DL focus more temporal dependencies than spatial and geographic information<br>GCN<br>HAGCN</p>
<h3 id="3preliminary"><a href="#3preliminary" class="headerlink" title="3preliminary"></a>3preliminary</h3><h4 id="problem-definition-of-RUL-prediction-with-GCN"><a href="#problem-definition-of-RUL-prediction-with-GCN" class="headerlink" title="problem definition of RUL prediction with GCN"></a>problem definition of RUL prediction with GCN</h4><p>for a graph G=(V,E,X) and label y<br>X change with time ,with constructd datasetD={(G1,y1),(G2,y2),……},the task of rul can mapping f:G-&gt;y</p>
<h4 id="temporal-dependency-modeling"><a href="#temporal-dependency-modeling" class="headerlink" title="temporal dependency modeling"></a>temporal dependency modeling</h4><p>BiLSTM</p>
<h4 id="spatial-dependency-modeling"><a href="#spatial-dependency-modeling" class="headerlink" title="spatial dependency modeling"></a>spatial dependency modeling</h4><p>by stacking graph convolution layers and graph pooling layers</p>
<p><strong>1.graph isomorphism convolution layer</strong></p>
<div align=center>
<img src="https://pic.imgdb.cn/item/656805ffc458853aef01eea2.png" >
</div>

<div align=center>
<img src="https://pic.imgdb.cn/item/656805ffc458853aef01ef50.png" >
</div>
GNN中aggregate和combine结合在一起

对于GIN
<div align=center>
<img src="https://pic.imgdb.cn/item/656805ffc458853aef01ef92.png" >
</div>

<p><strong>2.self-attention graph pooling</strong></p>
<div align=center>
<img src="https://pic.imgdb.cn/item/656805f8c458853aef01ddc1.png" >
</div>

<h3 id="4HAGCN"><a href="#4HAGCN" class="headerlink" title="4HAGCN"></a>4HAGCN</h3><h4 id="Regularized-self-attention-graph-pooling-layer"><a href="#Regularized-self-attention-graph-pooling-layer" class="headerlink" title="Regularized self-attention graph pooling layer"></a>Regularized self-attention graph pooling layer</h4><div align=center>
<img src="https://pic.imgdb.cn/item/656805f8c458853aef01dde8.png" >
</div>

<h4 id="Framework-of-HAGCN-for-RUL-prediction"><a href="#Framework-of-HAGCN-for-RUL-prediction" class="headerlink" title="Framework of HAGCN for RUL prediction"></a>Framework of HAGCN for RUL prediction</h4><div align=center>
<img src="https://pic.imgdb.cn/item/656805f4c458853aef01d40d.png" >
</div>

<h3 id="5case-study"><a href="#5case-study" class="headerlink" title="5case study"></a>5case study</h3><h4 id="CMAPSS"><a href="#CMAPSS" class="headerlink" title="CMAPSS"></a>CMAPSS</h4><p><strong>1.overview</strong></p>
<p><strong>2.data preprocessing</strong></p>
<p>按工况进行了数据标准化</p>
<p><strong>3.Constructing spatial-temporal graph datasets</strong></p>
<blockquote>
<p>for every time stamps constructing the graph G=(V,E,X)<br>V vetex set<br>E edge set<br>X 特征矩阵 (M,WL) WL:length of sliding window<br>A 连接矩阵 (2,|E|) |E|:number of edge  [[[[0,1,2],[1,2,3]]]] 代表0与1 ，1与2，,2与3相连 </p>
</blockquote>
<div align=center>
<img src="https://pic.imgdb.cn/item/656805f4c458853aef01d43c.png" >
</div>

<p><strong>input:</strong></p>
<p>X for M sensor use sliding window of length 30<br>A<br>把M个传感器当成M个点，用两个点的Euclidean distance判断两个node是否相连</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/656805f4c458853aef01d37e.png" >
</div>

<p>因为前面做过标准化</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/656805f4c458853aef01d3a3.png" >
</div>

<p>cos(Θ)即代表两个点的余弦相似度</p>
<p><strong>label</strong><br>piece-wise linear degradation</p>
<p><strong>4评价标准</strong><br>RMSE and SF</p>
<p><strong>5模型设置</strong></p>
<p>optimzer:</p>
<center>adam with lr decay</center>

<p>loss：</p>
<script type="math/tex; mode=display">
L{total} = L_{MSE}(ω)+ αL_{att}(Θ)</script><h3 id="6-model-analysis"><a href="#6-model-analysis" class="headerlink" title="6 model analysis"></a>6 model analysis</h3><p><strong>1The influence of prediction interval</strong></p>
<p><strong>2Ablation study and the importance analysis of RSAGPool</strong></p>
<div align=center>
<img src="https://pic.imgdb.cn/item/656805f0c458853aef01ca65.png" >
</div>

<p>Model I without the ability to model the temporal dependencies of the sensor measurements achieves the worst performance in these four models.Model II without the ability to model the spatial dependencies of the multiple sensors performs worse than Model III without ability to achieve hierarchical learning.</p>
<p><strong>3The influence of the attention loss of RSAGPool</strong><br>with the increase of alpha, especially when the training graphs come from a difficult dataset. This may be because the more complex the graph, the more difficult it is for the model to simultaneously focus on the importance of each node and learn the graph representation to make predictions. However, we can still observe that when the value of alpha is 100, HAGCN can achieve the best results on all datasets.</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/656805f0c458853aef01cadd.png" >
</div>

<p><strong>4The influence of number of HGRLs</strong></p>
<div align=center>
<img src="https://pic.imgdb.cn/item/656805f0c458853aef01ca03.png" >
</div>


<p><strong>5The graph topology learned by HAGCN</strong></p>
<div align=center>
<img src="https://pic.imgdb.cn/item/656805efc458853aef01c9a7.png" >
</div>


<p>GIN <a target="_blank" rel="noopener" href="https://www.cnblogs.com/akaman98/p/17355702.html(详">https://www.cnblogs.com/akaman98/p/17355702.html(详</a>)<br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/3b072a2813cf(略">https://www.jianshu.com/p/3b072a2813cf(略</a>)</p>
<p>SAGpooling <a target="_blank" rel="noopener" href="https://blog.csdn.net/yyl424525/article/details/103327551">https://blog.csdn.net/yyl424525/article/details/103327551</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://edmund199.github.io.git/2024/06/06/paper-note/RUL/Deep%20separable%20convolutional%20network%20for%20remaining%20useful%20life%20prediction%20of%20machinery/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="edmund">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | null">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/06/paper-note/RUL/Deep%20separable%20convolutional%20network%20for%20remaining%20useful%20life%20prediction%20of%20machinery/" class="post-title-link" itemprop="url">Deep separable convolutional network for remaining useful life prediction of machinery</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-06 14:01:07" itemprop="dateCreated datePublished" datetime="2024-06-06T14:01:07+08:00">2024-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-12-21 11:47:50" itemprop="dateModified" datetime="2023-12-21T11:47:50+08:00">2023-12-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/paper-note/" itemprop="url" rel="index"><span itemprop="name">paper note</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Deep-separable-convolutional-network-for-remaining-useful-life-prediction-of-machinery"><a href="#Deep-separable-convolutional-network-for-remaining-useful-life-prediction-of-machinery" class="headerlink" title="Deep separable convolutional network for remaining useful life prediction of machinery"></a>Deep separable convolutional network for remaining useful life prediction of machinery</h2><p><strong>2019 西安交通大学 8.4 1区 Mechanical Systems and Signal Processing</strong></p>
<h3 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h3><p>These deep learning-based prognostics approaches, however, have the following weaknesses: 1) Their prediction performance largely depends on the hand-crafted feature design. 2) The correlations of different sensor data are not explicitly considered in representation learning.</p>
<h3 id="1-introduction"><a href="#1-introduction" class="headerlink" title="1 introduction"></a>1 introduction</h3><ul>
<li>With the advancement of sensor technologies, telecommunications and computer science, industrial internet of things has been widely applied into health monitoring of machinery in recent years, and a considerable number of monitoring data are acquired by multiple sensors during machine operation.</li>
<li>In general,<strong>data-driven RUL prediction</strong> consists of four major processes: data acquisition, feature extraction and selection, degradation behavior learning and RUL estimation<br>Recently, <strong>deep learning</strong> [13] is gaining more and more attention in data-driven RUL prediction. </li>
<li>Although deep learning has achieved promising results in RUL prediction of machinery, existing prognostics approaches suffer from the following limitations. 1) Their prediction performance largely depends on the hand-crafted feature design in RUL prediction of many machines 2) Current deep prognostics models do not explicitly consider the correlations of different sensor data in representation learning.</li>
<li>To deal with the above-mentioned limitations, a new deep prognostics network, named deep separable convolutional network (DSCN), is proposed for RUL prediction of machinery in this paper.</li>
</ul>
<h3 id="2-preliminary"><a href="#2-preliminary" class="headerlink" title="2 preliminary"></a>2 preliminary</h3><h4 id="2-1Convolutional-networks"><a href="#2-1Convolutional-networks" class="headerlink" title="2.1Convolutional networks"></a>2.1Convolutional networks</h4><p>1) Convolutional layer.<br>2) Pooling layer.<br>3) Fully-connected layer.</p>
<h4 id="2-2-Residual-connections-for-convolutional-networks"><a href="#2-2-Residual-connections-for-convolutional-networks" class="headerlink" title="2.2. Residual connections for convolutional networks"></a>2.2. Residual connections for convolutional networks</h4><p>Residual connections are first proposed by He et al. in [27], aiming at reducing the training complexity of convolutional networks and enabling them to be substantially deeper.</p>
<h3 id="3-Proposed-DSCN-for-RUL-prediction-of-machinery"><a href="#3-Proposed-DSCN-for-RUL-prediction-of-machinery" class="headerlink" title="3 Proposed DSCN for RUL prediction of machinery"></a>3 Proposed DSCN for RUL prediction of machinery</h3><h4 id="3-1-Separable-convolutions"><a href="#3-1-Separable-convolutions" class="headerlink" title="3.1. Separable convolutions"></a>3.1. Separable convolutions</h4><p>multi-channel time-series data are usually used as the inputs of deep prognostics models, where each channel represents one sensor sequence,aiming to effectively model interrelationships of different sensor data by decoupling temporal correlations and cross-channel correlations.</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/657eb7f1c458853aefe27d21.png" >
</div>

<p>代码实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Separable_conv</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_ch, out_ch</span>):</span><br><span class="line">        <span class="built_in">super</span>(Separable_conv, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.channelwise_conv = nn.Conv1d(in_channels=in_ch,</span><br><span class="line">                                          out_channels=in_ch,</span><br><span class="line">                                          kernel_size=<span class="number">8</span>,</span><br><span class="line">                                          stride=<span class="number">1</span>,</span><br><span class="line">                                          groups=in_ch)</span><br><span class="line">        <span class="comment">#在创建conv1d时指定groups数量可以设定卷积核数量实现separable_conv</span></span><br><span class="line">        self.point_conv = nn.Conv1d(in_channels=in_ch,</span><br><span class="line">                                    out_channels=out_ch,</span><br><span class="line">                                    kernel_size=<span class="number">1</span>,</span><br><span class="line">                                    stride=<span class="number">1</span>,</span><br><span class="line">                                    padding=<span class="number">0</span>,</span><br><span class="line">                                    groups=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,<span class="built_in">input</span></span>):</span><br><span class="line">        <span class="built_in">input</span> = F.pad(<span class="built_in">input</span>=<span class="built_in">input</span>, pad=(<span class="number">4</span>,<span class="number">3</span>), mode=<span class="string">&#x27;constant&#x27;</span>, value=<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># print(input.shape)</span></span><br><span class="line">        out = self.channelwise_conv(<span class="built_in">input</span>)</span><br><span class="line">        out = self.point_conv(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<p><strong>conv1d中groups作用</strong></p>
<ul>
<li>groups: 控制输入和输出之间的连接， group=1，输出是所有的输入的卷积；group=2，此时相当于有并排的两个卷积层，每个卷积层计算输入通道的一半，并且产生的输出是输出通道的一半，随后将这两个输出连接起来。</li>
</ul>
<p>groups=1时与标准卷积一致，具体作用参考<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/616003771">1</a></p>
<h4 id="3-2-Feature-response-recalibrations"><a href="#3-2-Feature-response-recalibrations" class="headerlink" title="3.2. Feature response recalibrations"></a>3.2. Feature response recalibrations</h4><p>the process of feature response recalibrations is comprised of two steps, including squeeze operation and excitation operation.</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/657eb7f1c458853aefe27e00.png" >
</div>

<h4 id="3-3-Separable-convolutional-building-blocks"><a href="#3-3-Separable-convolutional-building-blocks" class="headerlink" title="3.3. Separable convolutional building blocks"></a>3.3. Separable convolutional building blocks</h4><div align=center>
<img src="https://pic.imgdb.cn/item/657eb7f2c458853aefe27e92.png" >
</div>

<p><strong>pre-activate</strong><br>BN and ReLU are added after convolution operations in the standard convolutional networks, but this postactivation strategy may not take full advantage of the benefits of BN in the convolutional networks with residual connections [33].the pre-activation strategy in [33] is also used to improve the regularization of DSCN so as to relieve the problem of overfitting.<br><strong>bn</strong><br>the use of BN is to make the input distribution of each separable convolution more stable and reduce the overfitting [34]. Further, BN is able to allow DSCN to use much higher learning rates and to be insensitive to the parameter initialization.<br><strong>identity skip connection</strong><br>kernel size为1<br>stride为4，为了与另一条conv输出特征一样的conv1d</p>
<h4 id="3-4-Architecture-of-the-proposed-DSCN"><a href="#3-4-Architecture-of-the-proposed-DSCN" class="headerlink" title="3.4. Architecture of the proposed DSCN"></a>3.4. Architecture of the proposed DSCN</h4><div align=center>
<img src="https://pic.imgdb.cn/item/657eb7f1c458853aefe27b76.png" >
</div>

<p>1) The representation learning sub-network firstly uses a separable convolutional layer to convolute the input sensor data，$\rightarrow$ an average pooling layer is employed to conduct down-sampling $\rightarrow$  forwarded to succeeding separable convolutional building blocks to obtain higher-level representations<br>2) The RUL estimation sub-network utilizes a global average pooling layer to receive the high-level representations from the representation learning sub-network,</p>
<h3 id="4-Experimental-verification"><a href="#4-Experimental-verification" class="headerlink" title="4. Experimental verification"></a>4. Experimental verification</h3><h4 id="4-1-Case-study-1-XJTU-SU-dataset"><a href="#4-1-Case-study-1-XJTU-SU-dataset" class="headerlink" title="4.1. Case study 1: XJTU-SU dataset"></a>4.1. Case study 1: XJTU-SU dataset</h4><p>4.1.1. Data description</p>
<p>4.1.2. Evaluation metrics</p>
<p>1) Scoring function<br>2) RMSE</p>
<p>4.1.3. Data preprocessing</p>
<p>1) Normalization<br>2) Time window embedding</p>
<p><strong>4.1.4. Configuration of DSCN</strong></p>
<div align=center>
<img src="https://pic.imgdb.cn/item/657eb7f1c458853aefe27bf7.png" >
</div>

<p>hyperparameters are determined by performing 4-fold cross-validation on the training datasets</p>
<p>the input to net is (batch_size,chanel,time_windows_lengh*time_sequence_length)<br>(128,2,5*2560)<br>the out put of net is (128)</p>
<p><strong>4.1.5. Experimental results</strong></p>
<p>1) Analysis of time window embedding<br>the time window embedding is able to gather more useful degradation information<br>2) Effect of dimensionality reduction ratio and network depth<br>The dimensionality reduction ratio r is a critical hyperparameter in the SE units, whose size may affect the capacity and computational cost of SE units.<br>3) Benefits of separable convolutions and feature response recalibrations<br>the network with standard convolutions (denoted as standard ConvNet) and the network with separable convolutions (denoted as separable ConvNet). Except for not containing the SE units, these two prognostics networks have the same architecture and hyperparameter settings as the proposed DSCN.</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/657eb835c458853aefe37206.png" >
</div>

<p>4) Comparison with state-of-the-art prognostics approaches<br>SVM [9], DBN [24], multi-scale CNN (MCNN) [25] and convolutional LSTM (CLSTM) [26].</p>
<h4 id="4-2-Case-study-2-Public-C-MAPSS-datasets"><a href="#4-2-Case-study-2-Public-C-MAPSS-datasets" class="headerlink" title="4.2. Case study 2: Public C-MAPSS datasets"></a>4.2. Case study 2: Public C-MAPSS datasets</h4><p>4.2.1. C-MAPSS datasets</p>
<p><strong>4.2.2. Prognostics results, comparison and discussion</strong></p>
<p>using min-max scaling [28]. In addition, a time window of size 30.piece-wise linear degradation assumption,the same configuration tabulated in Table 2 except for the time window size<br>the input of net is (batch_size,num_sensor,time_windows_lengh*time_sequence_length)<br>(128,14,30*1)</p>
<h3 id="5-Conclusions"><a href="#5-Conclusions" class="headerlink" title="5. Conclusions"></a>5. Conclusions</h3><p>引入可分离卷积操作来代替标准卷积操作，以有效地建模不同传感器数据之间的相互关系。同时，为了提高对信息特征图的敏感性，构建了一个SE单元来执行自适应特征响应重新校准<br>1）DSCN直接使用原始的多传感器数据作为输入，摆脱了手动特征提取和选择的复杂过程。2）DSCN明确考虑了不同传感器数据之间的相关性。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://edmund199.github.io.git/2024/06/06/paper-note/RUL/An%20enhanced%20encoder%E2%80%93decoder%20framework%20for%20bearing%20remaining%20useful%20life%20prediction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="edmund">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | null">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/06/paper-note/RUL/An%20enhanced%20encoder%E2%80%93decoder%20framework%20for%20bearing%20remaining%20useful%20life%20prediction/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-06 14:01:07" itemprop="dateCreated datePublished" datetime="2024-06-06T14:01:07+08:00">2024-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-13 19:55:40" itemprop="dateModified" datetime="2024-03-13T19:55:40+08:00">2024-03-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/paper-note/" itemprop="url" rel="index"><span itemprop="name">paper note</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="An-enhanced-encoder–decoder-framework-for-bearing-remaining-useful-life-prediction"><a href="#An-enhanced-encoder–decoder-framework-for-bearing-remaining-useful-life-prediction" class="headerlink" title="An enhanced encoder–decoder framework for bearing remaining useful life prediction"></a>An enhanced encoder–decoder framework for bearing remaining useful life prediction</h2><p><strong>2020.8 北航 5.6 2区 Measurement</strong></p>
<h3 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h3><p>This paper explores the degradation process of bearings and proposes an enhanced encoder–decoder framework. The framework attempts to construct a decoder with the ability to look back and selectively mine underlying information in the encoder.<br><strong>trigonometric functions and cumulative operation</strong> are employed to enhance the quality of <strong>health indicators.</strong></p>
<h3 id="1introduction"><a href="#1introduction" class="headerlink" title="1introduction"></a>1introduction</h3><p><strong>two types of bearing maintenance strategies</strong> :post-failure maintenance and scheduled maintenance<br> -&gt; <strong>three aproch</strong>:physical model-based methods [2,3], statistical model-based methods, and data-driven methods.<br>-&gt;<strong>two major challenges</strong>:health indicator (HI) construction, and prognostics model selection.</p>
<blockquote>
<p>hi构造的重要性：features with monotonicity tend to bring about better RUL prognostics results. Besides, some original features may fail to reflect the degradation tendency.<br>RNN缺陷：Additionally, the accuracy of existing RNN-based prognostics models decreases when time-series data covers the whole life of the machine, as too long sequence will result in vanishing or exploding gradient problems. On the other hand, short time-series cannot reflect the internal relationship and evolution trend.</p>
</blockquote>
<h3 id="2-Theoretical-framework"><a href="#2-Theoretical-framework" class="headerlink" title="2. Theoretical framework"></a>2. Theoretical framework</h3><div align=center>
<img src="" >
</div>








      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://edmund199.github.io.git/2024/06/06/paper-note/RUL/A%20deep%20attention%20residual%20neural%20network-based%20remaining%20useful%20life%20prediction%20of%20machinery/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="edmund">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | null">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/06/paper-note/RUL/A%20deep%20attention%20residual%20neural%20network-based%20remaining%20useful%20life%20prediction%20of%20machinery/" class="post-title-link" itemprop="url">A deep attention residual neural network-based remaining useful life prediction of machinery</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-06 14:01:07" itemprop="dateCreated datePublished" datetime="2024-06-06T14:01:07+08:00">2024-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-12-20 22:03:33" itemprop="dateModified" datetime="2023-12-20T22:03:33+08:00">2023-12-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/paper-note/" itemprop="url" rel="index"><span itemprop="name">paper note</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="A-deep-attention-residual-neural-network-based-remaining-useful-life-prediction-of-machinery"><a href="#A-deep-attention-residual-neural-network-based-remaining-useful-life-prediction-of-machinery" class="headerlink" title="A deep attention residual neural network-based remaining useful life prediction of machinery"></a>A deep attention residual neural network-based remaining useful life prediction of machinery</h2><p><strong>2021 东北大学 5.6 2区 measurement</strong></p>
<h3 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h3><p>这篇论文提出了一种新颖的深度注意力残差神经网络（DARNN）用于机械剩余寿命（RUL）的预测。DARNN可以有效提取信号中的降解特征，并且在预测性能和自稳定性上显著优于现有方法。</p>
<h3 id="1introduction"><a href="#1introduction" class="headerlink" title="1introduction"></a>1introduction</h3><p>PHM -&gt; Model-based approaches -&gt; The AI-based approach -&gt; deep learning (DL) -&gt; RNN models for RUL estimation -&gt; Although the above research has achieved great success, the following <strong>limitations</strong> still exist. (1) The performance of the data-driven model depends on a large amount of training data, and the prediction accuracy is still limited by the lack of training samples. (2) In practical application, the established model may be affected by noise, resulting in a serious decline in prediction accuracy.<br>-&gt; <strong>DARNN</strong> is proposed in this paper. The proposed method has the following advantages. (1) The proposed deep attention residual (DAR) module can effectively improve the feature extraction capability of the model and improve the prediction performance of the model. (2) The Bayesian approximation technique is applied to the established model to turn point forecasting into interval forecasting and improve the self-stability of the proposed model.</p>
<h3 id="2-Proposed-DARNN-model"><a href="#2-Proposed-DARNN-model" class="headerlink" title="2. Proposed DARNN model"></a>2. Proposed DARNN model</h3><div align=center>
<img src="https://pic.imgdb.cn/item/657f00b2c458853aef1653a0.png" >
</div>

<h4 id="2-1-DAR-module"><a href="#2-1-DAR-module" class="headerlink" title="2.1. DAR module"></a>2.1. DAR module</h4><div align=center>
<img src="https://pic.imgdb.cn/item/657f00b3c458853aef1654de.png" >
</div>

<p>2.1.1. Temporal convolution<br>Both causal convolution operation as well as dilation rate strategy are used in the temporal convolution to improve the representative extraction capability of the established DL model.<br>(1) Causal convolution:<br>(2) Dilation rate strategy:</p>
<p>2.1.2. PReLU activation function<br>‘‘Dead ReLU Problem’’ for using the ReLU activation function, i.e., during the process of training, when the weighted inputs of neurons are negative, outputs of neurons become 0 consistently</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/657f00b3c458853aef165522.png" >
</div>

<p>2.1.3. Dual attention mechanism</p>
<p>(1) Channel attention mechanism<br>The channel attention mechanism [28,29] is utilized to judge which channels are more informative, and an attention weights are given to each channel according to their importance.<br>(2) Temporal attention mechanism<br>Similar to the principle of channel attention mechanism, temporal attention mechanism is capable of aggregating some crucial information in the time dimension of feature maps.</p>
<div align=center>
<img src="https://pic.imgdb.cn/item/657f00b3c458853aef165637.png" >
</div>

<p>2.1.4. BayesIan approximation technique (Dropout)</p>
<p>To improve the self-stability of model, the Bayesian approximation technique is adopted in our DARNN to reduce the interference from environmental noise and turn point estimation into interval estimation</p>
<h4 id="2-2-Deep-domain-adaption"><a href="#2-2-Deep-domain-adaption" class="headerlink" title="2.2. Deep domain adaption"></a>2.2. Deep domain adaption</h4><p>In order to solve these two problems and improve the generalization ability of the established model, maximum mean discrepancy is applied to realize deep domain adaption.</p>
<h3 id="3-Case-study-1-FEMTO-dataset"><a href="#3-Case-study-1-FEMTO-dataset" class="headerlink" title="3. Case study 1: FEMTO dataset"></a>3. Case study 1: FEMTO dataset</h3><h4 id="3-1-Data-description"><a href="#3-1-Data-description" class="headerlink" title="3.1. Data description"></a>3.1. Data description</h4><p>z-score</p>
<h4 id="3-2-Prognostic-metrics"><a href="#3-2-Prognostic-metrics" class="headerlink" title="3.2. Prognostic metrics"></a>3.2. Prognostic metrics</h4><ol>
<li>RMSE</li>
<li>score</li>
<li>CRA is also used to illustrate performance of models. The closer the calculated CRA value is to 1, the smaller the relative error between the real values and the predicted values is. CRA is defined as:</li>
</ol>
<div align=center>
<img src="https://pic.imgdb.cn/item/657f00b2c458853aef165213.png" >
</div>

<h4 id="3-3-Hyperparameters-selection-of-DARNN"><a href="#3-3-Hyperparameters-selection-of-DARNN" class="headerlink" title="3.3. Hyperparameters selection of DARNN"></a>3.3. Hyperparameters selection of DARNN</h4><p>Rectified Adam (RAdam) Optimizer ,early stopping and gradient cropping<br>to promote the convergence of the model, the RUL label corresponding to the data is converted into RUL percentage for training.</p>
<h4 id="3-4-Ablation-studies"><a href="#3-4-Ablation-studies" class="headerlink" title="3.4. Ablation studies"></a>3.4. Ablation studies</h4><p>(1) Effectiveness of dual attention block:<br>a model without dual attention mechanism,</p>
<p>(2) Effectiveness of temporal convolution: Meanwhile, a model with traditional convolution is also established,</p>
<h4 id="3-5-Experiment-results-and-discussion"><a href="#3-5-Experiment-results-and-discussion" class="headerlink" title="3.5. Experiment results and discussion"></a>3.5. Experiment results and discussion</h4><p>3.5.1. Effectiveness of the proposed DARNN<br>the absolute value of Pearson correlation coefficient is adopted to evaluate the correlation between features and predicted values. The Pearson correlation coefficient is defined as</p>
<p>3.5.2. Comparison and discussion</p>
<p>3.5.3. Self-stability of the proposed DARNN<br>Signal–Noise ratio (SNR) is usually used to describe the level of noise in the signal, which is defined as</p>
<p><div align=center>
<img src="https://pic.imgdb.cn/item/657f00e0c458853aef1719f3.png" >
</div><br>where 𝑃𝑆 and 𝑃𝑁 denote the power of signal and noise respectively. The lower the SNR, the larger the random noise contained in the data, e.g., when the SNR equals 0 dB, the power of noise is equivalent to that of the original signal. In the experiment, signals with different levels of additive white Gaussian noise from −2 dB to 8 dB were used as noisy data.</p>
<h3 id="4-Case-study-2-CAMPSS-dataset"><a href="#4-Case-study-2-CAMPSS-dataset" class="headerlink" title="4. Case study 2: CAMPSS dataset"></a>4. Case study 2: CAMPSS dataset</h3><p>4.1. Dataset description and preprocessing<br>preprocess the training data set and the test data set by using min–max normalization and time window strategy, and the size of time window is 30.</p>
<p>4.2. Experiment results and discussion</p>
<h3 id="5-Conclusion"><a href="#5-Conclusion" class="headerlink" title="5. Conclusion"></a>5. Conclusion</h3><p>(1) In this paper, a DAR module is proposed to improve the representations extraction capability and prediction performance. Also, the Bayesian approximation technique is also applied to the proposed DARNN model to improve the self-stability of the DARNN model. (2) To demonstrate the effectiveness and superiority of the proposed DARNN, we organized two case study experiments. In the first case study, rolling element bearing dataset is adopted to illustrate the effectiveness and self-stability of the proposed DARNN model. In the second experiment, the famous CMAPSS dataset is utilized to further validate the effectiveness of the proposed model by making a comparison with the four state-of-art methods. The experimental results demonstrate the proposed model actually has better performance compared with other four data driven methods.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://edmund199.github.io.git/2024/06/06/new-study-note/new-study-note5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="edmund">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | null">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/06/new-study-note/new-study-note5/" class="post-title-link" itemprop="url">new-study-note5</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-06 14:01:07" itemprop="dateCreated datePublished" datetime="2024-06-06T14:01:07+08:00">2024-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-08 18:45:33" itemprop="dateModified" datetime="2024-03-08T18:45:33+08:00">2024-03-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/study-notes/" itemprop="url" rel="index"><span itemprop="name">study notes</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="wandb"><a href="#wandb" class="headerlink" title="wandb"></a>wandb</h2><ol>
<li><strong>基本使用（使用wandb替换tensorboard）</strong></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wandb</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># start a new wandb run to track this script</span></span><br><span class="line">wandb.init(</span><br><span class="line">    <span class="comment"># set the wandb project where this run will be logged</span></span><br><span class="line">    project=<span class="string">&quot;my-awesome-project&quot;</span>,</span><br><span class="line">    <span class="comment">#记录项目名称</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># track hyperparameters and run metadata</span></span><br><span class="line">    config=&#123;</span><br><span class="line">    <span class="string">&quot;learning_rate&quot;</span>: <span class="number">0.02</span>,</span><br><span class="line">    <span class="string">&quot;architecture&quot;</span>: <span class="string">&quot;CNN&quot;</span>,</span><br><span class="line">    <span class="string">&quot;dataset&quot;</span>: <span class="string">&quot;CIFAR-100&quot;</span>,</span><br><span class="line">    <span class="string">&quot;epochs&quot;</span>: <span class="number">10</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">#记录参数</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># simulate training</span></span><br><span class="line">epochs = <span class="number">10</span></span><br><span class="line">offset = random.random() / <span class="number">5</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, epochs):</span><br><span class="line">    acc = <span class="number">1</span> - <span class="number">2</span> ** -epoch - random.random() / epoch - offset</span><br><span class="line">    loss = <span class="number">2</span> ** -epoch + random.random() / epoch + offset</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># log metrics to wandb</span></span><br><span class="line">    wandb.log(&#123;<span class="string">&quot;acc&quot;</span>: acc, <span class="string">&quot;loss&quot;</span>: loss&#125;) <span class="comment">#选择要记录的数据</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># [optional] finish the wandb run, necessary in notebooks</span></span><br><span class="line">wandb.finish()</span><br></pre></td></tr></table></figure>
<p>将要记录的数据一次性记录下来使他们有相同的步长，也可以设置wandb记录的横坐标</p>
<ol>
<li><strong>想要科学上网和wandb一起使用（离线使用）</strong></li>
</ol>
<p>需求： 一般情况下挂VPN会导致wandb初始化出错，不能连接到wandb服务器进行数据同步上传，因此可以采用离线上传数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> wandb</span><br><span class="line">os.environ[<span class="string">&quot;WANDB_API_KEY&quot;</span>] = <span class="string">&#x27;自己的API KEY&#x27;</span> </span><br><span class="line">os.environ[<span class="string">&quot;WANDB_MODE&quot;</span>] = <span class="string">&quot;offline&quot;</span></span><br></pre></td></tr></table></figure>
<p>在导包时加上如上语句，在训练后在根据提升上传数据到网站上。</p>
<blockquote>
<p>使用命令wandb sync 数据地址 上传数据</p>
</blockquote>
<p>官方文档：<a target="_blank" rel="noopener" href="https://docs.wandb.ai/tutorials">https://docs.wandb.ai/tutorials</a></p>
<h2 id="使用小波包分解将一位时间数据转换为二维数据"><a href="#使用小波包分解将一位时间数据转换为二维数据" class="headerlink" title="使用小波包分解将一位时间数据转换为二维数据"></a>使用小波包分解将一位时间数据转换为二维数据</h2><p><strong>原理：</strong><br>小波包分解是常用的信号分析方法，能够将原始信号分解至多个频段，获得多组小波系数。<br>而这些小波系数可以堆叠在一起，构成二维的小波系数矩阵，如下图所示[1]。<br>值得注意的是，这个矩阵有着明确的意义：<strong>每一行表示了某个具体频段的信息。</strong></p>
<div align=center>
<img src= >
</div>

<p>更进一步地，在小波包分解时，可以采用多个小波基函数，从而获得多个二维矩阵，堆叠成三维矩阵[2]。</p>
<div align=center>
<img src= >
</div>

<h2 id="VAE-变分自动编码器"><a href="#VAE-变分自动编码器" class="headerlink" title="VAE(变分自动编码器)"></a>VAE(变分自动编码器)</h2><h3 id="VAE的基本架构"><a href="#VAE的基本架构" class="headerlink" title="VAE的基本架构"></a>VAE的基本架构</h3><p>由AE发展而来，却不同于AE，属于生成模型的一种。<br>与普通自动编码器一样，变分自动编码器有编码器Encoder与解码器Decoder两大部分组成，原始图像从编码器输入，经编码器后形成隐式表示（Latent Representation），之后隐式表示被输入到解码器、再复原回原始输入的结构。然而，与普通Autoencoders不同的是，<strong>变分自用编码器的Encoder与Decoder在数据流上并不是相连的，我们不会直接将Encoder编码后的结果传递给Decoder，而是要使得隐式表示满足既定分布。</strong></p>
<p>具体流程如下：</p>
<blockquote>
<p>①首先，变分自动编码器中的编码器会尽量将样本$X$所携带的所有特征信息的分布转码成类高斯分布。<br>②编码器需要输出该类高斯分布的均值$\mu$与标准差$\sigma$作为编码器的输出。<br>③以编码器生成的均值$\mu$与标准差$\sigma$为基础构建高斯分布。<br>④从构建的高斯分布中随机采样出一个数值$Z$，将该数值输入解码器。<br>⑤解码器基于$Z$进行解码，并最终输出与样本的原始特征结构一致的数据，作为VAE的输出$X$′。</p>
</blockquote>
<div align=center>
<img src= >
</div>


<p>根据以上流程，变分自动编码器的Encoder在输出时，并不会直接输出原始数据的隐式表示，而是会输出从原始数据提炼出的均值和标准差。之后，我们需要建立均值为、标准差为的正态分布，并从该正态分布中抽样出隐式表示z，再将隐式表示z输入到Decoder中进行解码。对隐式表示z而言，它传递给Decoder的就不是原始数据的信息，而只是与原始数据同均值、同标准差的分布中的信息了。这样做就正好印证了3.1节提出背景中的两点：</p>
<ol>
<li>斩断了神经网络中惯例的“从输入到输出”的数据流，以此杜绝了信息直接被复制到输出层的可能性。</li>
<li>使得编码器具有以满足特定分布数据的输入到输出的能力，也就是解码器的生成能力。<br>由于第④步采样的存在，使得VAE的整体过程较为复杂，下面将一步步拆解。</li>
</ol>
<h3 id="VAE的正向传播"><a href="#VAE的正向传播" class="headerlink" title="VAE的正向传播"></a>VAE的正向传播</h3><p>m个样本每个样本生成一组标准差和均值</p>
<div align=center>
<img src= >
</div>

<p>在变分自动编码器的流程当中，<strong>均值和标准差都不是通过他们的数学定义计算出来的，而是通过Encoder提炼出来的</strong>。这就是说<strong>当前的均值和标准差不是真实数据的统计量，而是通过Encoder推断出的、当前样本数据可能服从的任意分布中的属性</strong>。我们不可能知道当前样本服从的真实分布的状态，因此这一推断过程自然可以根据不同的规则（Encoder中不同的权重）得出不同的结果。</p>
<p>例如，我们可以令Encoder的输出层存在3个神经元，这样Encoder就会对每一个样本推断出三对不同的均值和标准差。这个行为相当于对样本数据所属的原始分布进行估计，但给出了三个可能的答案。因此现在，在每个样本下，我们就可以基于三个均值和标准差的组合生成三个不同的正态分布了。</p>
<div align=center>
<img src= >
</div>

<p>对任意的自动编码器而言，隐式空间越大，隐式表示z所携带的信息自然也会越多，自动编码器的表现就可能变得更好，因此在实际使用变分自动编码器的过程中，一个样本上至少都会生成10~100组均值和标准差，隐式表示z的结构一般也是较高维的矩阵。</p>
<p><strong>变分自动编码器有如下的三个特点：</strong></p>
<ul>
<li>斩断了神经网络中惯例的“从输入到输出”的数据流，以此<strong>杜绝了信息直接被复制到输出层的可能性。</strong></li>
<li><strong>无论在训练还是预测过程中，模型都存在随机性</strong>，相比之下，大部分带有随机性的算法只会在训练的过程中有随机性，而在测试过程中对模型进行固定。但由于变分自动编码器的“随机性”是与网络架构及输入数据结构都高度相关的随机性，因此当训练数据变化的时候，随机抽样的情况也会跟着变化。</li>
<li><strong>可以作为生成模型使用</strong>。其他的自动编码器都是在原始图像上进行修改，而变分自动编码器可以从无到有生成与训练集高度相似的数据。由于输入Decoder的信息只是从正态分布中抽选的随机样本，因此其本质与随机数差异不大，当我们训练完变分自动编码器之后，就可以只使用解码器部分，只要对解码器输入结构正确随机数/随机矩阵，就可以生成与训练时所用的真实数据高度类似的数据。</li>
</ul>
<h3 id="VAE的损失函数"><a href="#VAE的损失函数" class="headerlink" title="VAE的损失函数"></a>VAE的损失函数</h3><ul>
<li>第一部分：<strong>让编码器输出的概率分布和我们的先验的概率分布一样，这样就能够完成我们的生成任务。这一项是为了将数据的分布训练成为指定概率分布，方便生成任务的。</strong></li>
<li>第二部分：<strong>为了保证输出的精度，还需要让模型的输出与输入满足一定的关系。这又叫重构损失，例如可以看作回归任务的MSE，亦可能是交叉熵等其他损失函数。这一项是衡量模型输入与输出的关系的。</strong></li>
</ul>
<div align=center>
<img src= >
</div>

<h3 id="VAE的重参数化"><a href="#VAE的重参数化" class="headerlink" title="VAE的重参数化"></a>VAE的重参数化</h3><p>现在我们已经了解了变分自动编码器的基本流程和训练目标，那我们是否可以尝试着手动去实现变分自动编码器了呢？有一个隐藏的陷阱还没有被我们注意到，那就是前面讲过的VAE为了<strong>杜绝了信息直接被复制到输出层的可能性</strong>，斩断了神经网络中惯例的“从输入到输出”的数据流，用采样来连接网络的编码器与解码器。由<strong>于这个抽样流程的存在，架构中的数据流是断裂的，因此反向传播无法进行。反向传播要求每一层数据之间必有函数关系，而抽样流程不是一个函数关系，因此无法被反向传播</strong>。为了解决这一问题，变分自动编码器的原始论文提出了<strong>重参数化技巧，这一技巧可以帮助我们在抽样的同时建立$\mu$与$z$和$\sigma$之间的函数关系，这样就可以令反向传播顺利进行了。</strong></p>
<div align=center>
<img src= >
</div>

<p>VAE:<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/628604566">https://zhuanlan.zhihu.com/p/628604566</a></p>
<p>todo</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://edmund199.github.io.git/2024/06/06/new-study-note/new-study-note4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="edmund">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | null">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/06/new-study-note/new-study-note4/" class="post-title-link" itemprop="url">new-study-note4</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-06 14:01:07" itemprop="dateCreated datePublished" datetime="2024-06-06T14:01:07+08:00">2024-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-01-26 11:27:52" itemprop="dateModified" datetime="2024-01-26T11:27:52+08:00">2024-01-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/study-notes/" itemprop="url" rel="index"><span itemprop="name">study notes</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="数据扩充"><a href="#数据扩充" class="headerlink" title="数据扩充"></a>数据扩充</h2><p>对于时间序列，当数据长度不满足于time_window时可以采用插值或填充首数据的方法获取数据（对于CMAPSS数据集）。</p>
<h3 id="插值：todo"><a href="#插值：todo" class="headerlink" title="插值：todo"></a>插值：todo</h3><h3 id="拟合"><a href="#拟合" class="headerlink" title="拟合"></a>拟合</h3><p>多项式拟合（Polynomial Fitting）：多项式拟合是一种基本的拟合方法，它使用多项式函数来逼近数据。多项式拟合可以通过最小二乘法（Least Squares Method）或使用多项式拟合函数（如<code>numpy.polyfit</code>）来实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例散点数据</span></span><br><span class="line">x_data = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">y_data = np.array([<span class="number">1.2</span>, <span class="number">1.9</span>, <span class="number">3.2</span>, <span class="number">4.1</span>, <span class="number">5.5</span>, <span class="number">6.8</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拟合多项式的阶数</span></span><br><span class="line">degree = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 多项式拟合</span></span><br><span class="line">coefficients = np.polyfit(x_data, y_data, degree)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据拟合系数生成拟合曲线的x值</span></span><br><span class="line">x_fit = np.linspace(<span class="built_in">min</span>(x_data), <span class="built_in">max</span>(x_data), <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算拟合曲线的y值</span></span><br><span class="line">y_fit = np.polyval(coefficients, x_fit)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制原始散点和拟合曲线</span></span><br><span class="line">plt.scatter(x_data, y_data, label=<span class="string">&#x27;Data&#x27;</span>)</span><br><span class="line">plt.plot(x_fit, y_fit, <span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;Fit&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Polynomial Fitting&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#具体例子</span></span><br><span class="line"><span class="comment">#多项式拟合</span></span><br><span class="line">data = np.zeros((time_window, self.x.shape[<span class="number">1</span>]))</span><br><span class="line"><span class="comment">#对每一列数据单独计算</span></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(data.shape[<span class="number">1</span>]):</span><br><span class="line">    x_old = np.linspace(<span class="number">0</span>, <span class="built_in">len</span>(self.x)-<span class="number">1</span>, <span class="built_in">len</span>(self.x), dtype=np.float64)</span><br><span class="line">    <span class="comment">#用原来的数据通过polyfit求出参数</span></span><br><span class="line">    params = np.polyfit(x_old, self.x[:, j].flatten(), deg=<span class="number">1</span>)</span><br><span class="line">    k = params[<span class="number">0</span>]</span><br><span class="line">    b = params[<span class="number">1</span>]</span><br><span class="line">    x_new = np.linspace(<span class="number">0</span>, time_window-<span class="number">1</span>, time_window, dtype=np.float64)</span><br><span class="line">    <span class="comment">#用新的x和参数计算新的值</span></span><br><span class="line">    data[:, j] = (x_new * <span class="built_in">len</span>(self.x) / time_window * k + b)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="other"><a href="#other" class="headerlink" title="other"></a>other</h3><p>直接用首第一个元素pad成time_window长度，对于ndarry可以直接用np.pad</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data=np.pad(self.x, ((time_window - self.x.shape[0], 0), (0, 0)), &#x27;edge&#x27;)</span><br><span class="line">X=data[:, 5:-2]</span><br></pre></td></tr></table></figure>
<h2 id="轴承故障诊断-振动信号分析"><a href="#轴承故障诊断-振动信号分析" class="headerlink" title="轴承故障诊断-振动信号分析"></a>轴承故障诊断-振动信号分析</h2><h3 id="时域"><a href="#时域" class="headerlink" title="时域"></a>时域</h3><h4 id="时域波形"><a href="#时域波形" class="headerlink" title="时域波形"></a>时域波形</h4><h3 id="频域"><a href="#频域" class="headerlink" title="频域"></a>频域</h3><h4 id="FFT"><a href="#FFT" class="headerlink" title="FFT"></a>FFT</h4><p>通过频谱分析我们可以将信号从其原始的时间域（即随时间变化的形式）转换到频域（即按频率分布的形式）。<br>然而，传统的傅里叶变换有一个限制：它假设信号是平稳的，即其频率成分不会随时间改变。</p>
<h4 id="频谱"><a href="#频谱" class="headerlink" title="频谱"></a>频谱</h4><p>傅里叶谱（即频谱）表示：某一点频率上的幅值表示在整个信号里和在整个时间范围内，有一个含有此频率的三角函数组分。（横坐标为频率，纵坐标为幅值）</p>
<h4 id="包络谱"><a href="#包络谱" class="headerlink" title="包络谱"></a>包络谱</h4><p>包络谱：对信号进行hilbert变换之后，然后取极值，然后对取极值之后得到的一维数据取包络，对包络信号进行FFT变换得到的数据。（横坐标为频率，纵坐标为幅值）包络谱对冲击事件的故障比较敏感。包络谱图中各频率幅值的分布与的频谱图有所区别。频谱图中故障特征频率幅值较小，包络谱图中故障特征频率的幅值很高，窖易辨认。闪此，相对对于频谱分析，包络谱分析剔除了不必要的频率干扰，更能够凸显故障特征频率。根据包络谱图能更容易地对滚动轴承的故障种类进行判断。</p>
<p>频谱与包络谱的频率分布没有多大关系，①<strong>包络谱峰值较高的地方表示原始信号在该频率处有对应的频率分量</strong>；<strong>频谱峰值高的地方表示</strong>在整个信号里和在整个时间范围内，<strong>有一个含有此频率的三角函数组分</strong>。②频谱是直接对原信号做fft；包络谱是对原信号做hilbert变换之后的曲线取的包络线进行fft，得到的频域曲线理应不同。</p>
<h3 id="时频域"><a href="#时频域" class="headerlink" title="时频域"></a>时频域</h3><h4 id="STFT"><a href="#STFT" class="headerlink" title="STFT"></a>STFT</h4><p>对FFT进行加窗</p>
<p>在短时傅里叶变换（STFT）中，窗口函数及其大小选择是分析的关键。窗口函数决定了在任何给定时间点，信号的哪一部分被用于分析。窗口大小的选择直接影响了分析结果的时间分辨率和频率分辨率，这是进行有效STFT分析的最重要的权衡。</p>
<p>窗口大小的时间分辨率影响：时间分辨率与窗口的宽度密切相关。一个窄窗口提供较高的时间分辨率，因为它捕捉了信号在很短时间内的变化。这对于分析包含快速变化的瞬态事件，如敲击声或爆炸声，是非常有用的。然而，较小的窗口将限制频率分辨率，因为频率分析需要足够的周期来准确估计。</p>
<p>窗口大小的频率分辨率影响：频率分辨率与窗口的宽度呈反比。一个宽窗口覆盖了信号的较长时间段，提供了较高的频率分辨率。这是因为更多的周期可以在窗口内被分析，从而更准确地确定低频成分。但是，这会牺牲时间分辨率，因为窗口中的信号被假定在这段时间内是平稳的。</p>
<h4 id="CWT"><a href="#CWT" class="headerlink" title="CWT"></a>CWT</h4><p>高频部分具有较高的时间分辨率和较低的频率分辨率，而低频部分具有较高的频率分辨率和较低的时间分辨率，这就恰好解决了STFT的痛点。（PS：小波是复信号，上图中只画了实部投影）</p>
<h3 id="参考链接："><a href="#参考链接：" class="headerlink" title="参考链接："></a>参考链接：</h3><p>插值与拟合：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_45927003/article/details/120310513">https://blog.csdn.net/qq_45927003/article/details/120310513</a><br>python常见拟合方法：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/671063617">https://zhuanlan.zhihu.com/p/671063617</a></p>
<p>从傅里叶变换，到短时傅里叶变换，再到小波分析（CWT：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/589651368">https://zhuanlan.zhihu.com/p/589651368</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://edmund199.github.io.git/2024/06/06/new-study-note/new-study-note3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="edmund">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | null">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/06/new-study-note/new-study-note3/" class="post-title-link" itemprop="url">new-study-note3</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-06 14:01:07" itemprop="dateCreated datePublished" datetime="2024-06-06T14:01:07+08:00">2024-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-12-14 10:26:50" itemprop="dateModified" datetime="2023-12-14T10:26:50+08:00">2023-12-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/study-notes/" itemprop="url" rel="index"><span itemprop="name">study notes</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="tensorboard的使用"><a href="#tensorboard的使用" class="headerlink" title="tensorboard的使用"></a>tensorboard的使用</h2><h3 id="一、创建一个writer实例"><a href="#一、创建一个writer实例" class="headerlink" title="一、创建一个writer实例"></a>一、创建一个writer实例</h3><p>tensorboard的所有记录操作都是实例化了SummaryWriter这个对象，首先需要创建一个writer实例，有如下几种创建方式，如果创建writer时没有参数，默认文件在runs目录下，默认的子文件夹名字为该文件的创建日期，当然也可以手动设定子文件夹的名字</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorboardX <span class="keyword">import</span> SummaryWriter </span><br><span class="line"></span><br><span class="line"><span class="comment"># SummaryWriter encapsulates everything </span></span><br><span class="line">writer = SummaryWriter()</span><br></pre></td></tr></table></figure>
<h3 id="二、添加数据形式"><a href="#二、添加数据形式" class="headerlink" title="二、添加数据形式"></a>二、添加数据形式</h3><ol>
<li>记录标量<br>记录一个标量<br><code>add_scalar(tag, scalar_value, global_step, walltime)</code></li>
</ol>
<ul>
<li>tag：数据标签</li>
<li>scalar_value：数据的值，即y轴的值</li>
<li>global_step：全局步数，即x轴的值</li>
<li>walltime：记录event的时间，可选</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="built_in">range</span>(<span class="number">100</span>) </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> x:     </span><br><span class="line">    time.sleep(<span class="number">0.1</span>)</span><br><span class="line">    writer.add_scalar(<span class="string">&#x27;y=2x&#x27;</span>, i * <span class="number">2</span>, i, walltime=time.time()) </span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<p>记录多个标量<br><code>add_scalars(main_tag, scalar_dict, global_step, walltime)</code></p>
<ul>
<li>main_tag：数据标签</li>
<li>tag_scalar_dict：数据的值，即y轴的值</li>
<li>global_step：全局步数，即x轴的值</li>
<li>walltime：记录event的时间，可选</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorboardX <span class="keyword">import</span> </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">SummaryWriter writer = SummaryWriter() </span><br><span class="line">r = <span class="number">5</span> </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):     </span><br><span class="line">    writer.add_scalars(<span class="string">&#x27;run_14h&#x27;</span>, </span><br><span class="line">    				  &#123;<span class="string">&#x27;xsinx&#x27;</span>:i*np.sin(i/r),                                                                               </span><br><span class="line">					   <span class="string">&#x27;xcosx&#x27;</span>:i*np.cos(i/r),</span><br><span class="line">                       <span class="string">&#x27;tanx&#x27;</span>: np.tan(i/r)&#125;, </span><br><span class="line">                       i) </span><br><span class="line">writer.close() </span><br><span class="line"><span class="comment"># This call adds three values to the same scalar plot with the tag</span></span><br></pre></td></tr></table></figure>
<h3 id="三、运行tensorboard"><a href="#三、运行tensorboard" class="headerlink" title="三、运行tensorboard"></a>三、运行tensorboard</h3><p>当程序运行完成后会自动生成tensorboard文件和目录，在cmd终端使用<code>tensorboard --logdir=&lt;your_log_dir&gt;</code>运行日志进行可视化了</p>
<h2 id="Additive-Attention-和-Dot-product-Attention"><a href="#Additive-Attention-和-Dot-product-Attention" class="headerlink" title="Additive Attention 和 Dot-product Attention"></a>Additive Attention 和 Dot-product Attention</h2><p>additive attention 和 dot-product attention 是最常用的两种attention函数，都是用于在attention中计算两个向量之间的相关度，下面对这两个function进行简单的比较整理。</p>
<p><strong>计算原理</strong><br><code>additive attention</code>使用了一个有一个隐层的前馈神经网络，输入层是两个向量的横向拼接，输出层的激活函数是sigmoid表示二者的相关度，对每一对向量都需要进行一次计算，得到的结果再计算softmax得到attention相关度权重。<br>举个栗子<br>计算向量Q与向量K1，K2，… ，Kn的attention权重，先拼接Q-K1计算，再拼接Q-K2计算，…，直到所有的都计算出一个结果再套softmax。</p>
<p><code>dot-product attention</code>一般用矩阵运算，Q K V 分别是三个矩阵，均表示一组向量，dot-product attention想做的是如何用V中的向量表示Q，Q一般指的是要表示的目标，K要和Q建立联系，计算相关性，以计算出的相关性为权重，加权叠加矩阵V中的向量。下图是Transformer中用的dot-product attention，根号dk作用是缩放，一般的dot-product attention可以不用缩放。</p>
<p>这里Q和K的都是由维度为dk的向量组成的，V的维度为dv，最终生成的Q‘也是由维度为dv的向量组成的。<br>用同一个栗子，这里的矩阵Q 就是 1 × dk，K是 n × dk，V是 n × dv。</p>
<h2 id="argparse-ArgumentParser-用法解析"><a href="#argparse-ArgumentParser-用法解析" class="headerlink" title="argparse.ArgumentParser()用法解析"></a>argparse.ArgumentParser()用法解析</h2><ol>
<li>import argparse ；首先导入该模块</li>
<li>parser = argparse.ArgumentParser()；创建一个解析对象</li>
<li>parser.add_argument()；然后向该对象中添加要关注的命令行参数和选项，每一个add_argument方法对应一个要关注的参数或选项；</li>
<li>parser.parse_args()；调用parse_args()方法进行解析，解析成功之后即可使用。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="comment">#设置可选参数（常用）</span></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">&#x27;姓名&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--family&#x27;</span>, defalut=<span class="string">&#x27;chen&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">str</span>,<span class="built_in">help</span>=<span class="string">&#x27;姓&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--name&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,<span class="built_in">help</span>=<span class="string">&#x27;名&#x27;</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用args.参数名即可调用对应参数</span></span><br><span class="line"><span class="built_in">print</span>(args.family)</span><br></pre></td></tr></table></figure>
<h2 id="Python-pandas-DataFrame-ewm函数方法的使用"><a href="#Python-pandas-DataFrame-ewm函数方法的使用" class="headerlink" title="Python pandas.DataFrame.ewm函数方法的使用"></a>Python pandas.DataFrame.ewm函数方法的使用</h2><p><code>DataFrame.ewm(self, com=None, span=None, halflife=None, alpha=None, min_periods=0, adjust=True, ignore_na=False, axis=0)</code><br><code>Returns:pandas.api.typing.ExponentialMovingWindow</code></p>
<ul>
<li>com ：  float，可选<br>根据质心指定衰减， α=1/(1+com), for com≥0。</li>
<li>span ：  float，可选<br>根据范围指定衰减， α=2/(span+1), for span≥1。</li>
<li>halflife ：  float，可选<br>根据半衰期指定衰减， α=1−exp(log(0.5)/halflife),forhalflife&gt;0。</li>
<li>alpha ：  float，可选<br>直接指定平滑系数α， 0&lt;α≤1。</li>
<li>min_periods ： int，默认0<br>窗口中具有值的最小观察数（否则结果为NA）。</li>
<li>adjust ： bool，默认为True<br>除以开始阶段的衰减调整因子，以解释相对权重的不平衡(将EWMA视为移动平均线)。</li>
<li>ignore_na ： bool，默认为False<br>计算权重时忽略缺失值；指定True可重现0.15.0之前的行为。</li>
<li>axis ： {0或’index’，1或’columns’}，默认0<br>要使用的轴。值0标识行，值1标识列。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;B&#x27;</span>: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, np.nan, <span class="number">4</span>]&#125;)</span><br><span class="line"></span><br><span class="line">df.ewm(com=<span class="number">1</span>).mean()</span><br></pre></td></tr></table></figure>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>Additive Attention 和 Dot-product Attention<br><a target="_blank" rel="noopener" href="https://www.zhihu.com/tardis/bd/art/366993073?source_id=1001">https://www.zhihu.com/tardis/bd/art/366993073?source_id=1001</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://edmund199.github.io.git/2024/06/06/new-study-note/new-study-note2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="edmund">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | null">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/06/06/new-study-note/new-study-note2/" class="post-title-link" itemprop="url">GCN</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-06 14:01:07" itemprop="dateCreated datePublished" datetime="2024-06-06T14:01:07+08:00">2024-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-11-28 12:53:21" itemprop="dateModified" datetime="2023-11-28T12:53:21+08:00">2023-11-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/study-notes/" itemprop="url" rel="index"><span itemprop="name">study notes</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="什么是图"><a href="#什么是图" class="headerlink" title="什么是图"></a>什么是图</h2><p>A graph represents the relations (edges) between a collection of entities (nodes).</p>
<p>G=(V,E,U)<br>Vertex (or node) attributes<br>Edge (or link) attributes and directions<br>Global (or master node) attributes</p>
<h2 id="GCN"><a href="#GCN" class="headerlink" title="GCN"></a>GCN</h2><p>图卷积网络的本质就是提取图结构的空间特征，基于提取方式的不同可以分为：基于空间域的图网络（GraphSAGE，GAT，MPNN等）、基于谱域的图网络（Spectral CNN、ChebyNet、GCN等）。</p>
<blockquote>
<p>①基于空间的方法就是直接从图结构出发，聚合邻居节点的信息作为新的特征，不断的进行消息传递的过程。<br>②基于谱域的方法就是将原始数据转换至谱域中，利用图谱理论，引入滤波器进行滤波，在转换回时域的一个过程。</p>
</blockquote>
<h3 id="从空间域理解"><a href="#从空间域理解" class="headerlink" title="从空间域理解"></a>从空间域理解</h3><p>图网络的计算就是不断考虑邻居及自身信息的一个迭代过程，每进行一次迭代就是一次特征重组，下一层的特征为上一层特征的图卷积。<br>对于图网络的特征矩阵X</p>
<script type="math/tex; mode=display">
X^{l+1}=\widetilde{D}^{-1/2}\widetilde{A}\widetilde{D}^{-1/2}X^l</script><p>其中</p>
<script type="math/tex; mode=display">
考虑自身信息的邻接矩阵\widetilde{A}=A+I
\\D为度矩阵\widetilde{D}=D+I</script><p>度矩阵就是与该节点相邻节点的数据，因此就是邻接矩阵A每一行的求和组成的对角阵，</p>
<div align=center>
<img src=https://pic.imgdb.cn/item/656571bfc458853aefc588ef.png >
</div>

<div align=center>
<img src= https://pic.imgdb.cn/item/656571bfc458853aefc58c48.png>
</div>

<div align=center>
<img src= https://pic.imgdb.cn/item/656571bec458853aefc58738.png>
</div>

<p>基础的GCN信息传递的权重是通过度矩阵也既与节点相连的节点数得来的，GCN的权重还可以通过注意力机制获得称为GAT</p>
<div align=center>
<img src=https://pic.imgdb.cn/item/656571bfc458853aefc58a8a.png >
</div>

<h3 id="从频域理解"><a href="#从频域理解" class="headerlink" title="从频域理解"></a>从频域理解</h3><p>todo</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><h3 id="torch-geometric库用来构造GNN"><a href="#torch-geometric库用来构造GNN" class="headerlink" title="torch_geometric库用来构造GNN"></a>torch_geometric库用来构造GNN</h3><h4 id="实例化一个图"><a href="#实例化一个图" class="headerlink" title="实例化一个图"></a>实例化一个图</h4><p>图一般被用来建模和描述目标（节点）间成对的关系（边）。在Pytorch Gemometric（以后均简称pyg）中，一个图是由<em>torch_geometric.data.Data</em>的一个实例来描述的，<br>设此图有N个节点，每个节点有n个特征，M条边，每条边有m个特征，默认情况下拥有如下的属性：</p>
<p><strong>data.x</strong>: 节点的特征矩阵，形状：[N，n]<br><strong>data.edge_index</strong>: 用COO格式储存的图数据，形状：[2,M]（如不理解没事，后面我会在栗子中详细介绍），数据类型是torch.long<br>ex:[[0,1,2,3],[1,1,2,2]] 0,1,2,3分别与1,1,2,2相连<br><strong>data.edge_attr</strong>: 边特征矩阵，形状[M，m]<br><strong>data.y</strong>: 要训练的目标（可以是任意形状），如节点级目标[节点数，<em>]，图级目标[1,</em>]（寿命预测常用，用rul作为图的label）,此处<em>代表样本数量。<br><em>*data.pos</em></em>: 节点位置矩阵，形状：[N,num_dimensions],在有些图中，节点是具有坐标属性，比如3D点云，每个节点都是3维空间中的一个坐标，类似的也可以是其它维度的。<br>这些属性都不是必须属性，实际上Data对象并不局限于这些属性。例如：我们可以通过data.face来扩展它，用以保存形状为[3，num_Faces]（数据类型为torch.long）的三维网格中三角形的连通性。</p>
<h4 id="PyG的DataLoader"><a href="#PyG的DataLoader" class="headerlink" title="PyG的DataLoader"></a>PyG的DataLoader</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_scatter <span class="keyword">import</span> scatter_mean</span><br><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> TUDataset</span><br><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">dataset = TUDataset(root=<span class="string">&#x27;/tmp/ENZYMES&#x27;</span>, name=<span class="string">&#x27;ENZYMES&#x27;</span>, use_node_attr=<span class="literal">True</span>)</span><br><span class="line">loader = DataLoader(dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> loader:</span><br><span class="line">    data</span><br><span class="line">    &gt;&gt;&gt; Batch(batch=[<span class="number">1082</span>], edge_index=[<span class="number">2</span>, <span class="number">4066</span>], x=[<span class="number">1082</span>, <span class="number">21</span>], y=[<span class="number">32</span>])</span><br><span class="line"></span><br><span class="line">    data.num_graphs</span><br><span class="line">    &gt;&gt;&gt; <span class="number">32</span></span><br><span class="line"></span><br><span class="line">    x = scatter_mean(data.x, data.batch, dim=<span class="number">0</span>)</span><br><span class="line">    x.size()</span><br><span class="line">    &gt;&gt;&gt; torch.Size([<span class="number">32</span>, <span class="number">21</span>])</span><br></pre></td></tr></table></figure>
<p>torch_geometric.data.Batch 继承自 torch_geometric.data.Data 并且包含了一个额外的属性：batch.<br>batch 是一个列向量，它将整个图的所有节点映射到不同的批次中。</p>
<h4 id="基础的GCN"><a href="#基础的GCN" class="headerlink" title="基础的GCN"></a>基础的GCN</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GCNConv</span><br><span class="line"></span><br><span class="line">self.conv1 = GCNConv(num_node_features,num_hidden) <span class="comment">#实例化</span></span><br><span class="line">x = self.conv1(x, edge_index) <span class="comment">#前先传播</span></span><br></pre></td></tr></table></figure>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><p>GCN空间和频域理解<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/633419078?utm_id=0">https://zhuanlan.zhihu.com/p/633419078?utm_id=0</a></p>
<p>GCN原理<br><a target="_blank" rel="noopener" href="https://distill.pub/2021/gnn-intro/">https://distill.pub/2021/gnn-intro/</a></p>
<p>PyG文档之二：快速入门<a target="_blank" rel="noopener" href="https://blog.csdn.net/Yichar/article/details/107856411">https://blog.csdn.net/Yichar/article/details/107856411</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">edmund</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
